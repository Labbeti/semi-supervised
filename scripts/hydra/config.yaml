hardware:
  nb_cpu: 4
  nb_gpu: 1
dataset:
  dataset: gsc
  num_classes: 35
model:
  model: wideresnet28_2
train_param:
  supervised_ratio: 0.1
  batch_size: 64
  nb_epoch: 200
  learning_rate: 0.001
  seed: 1234
  resume: false
  train_folds: null
  val_folds: null
mt:
  alpha: 0.999
  warmup_length: 50
  lambda_ccost_max: 1
  use_softmax: true
  ccost_method: mse
mixup:
  use: true
  alpha: 1.0
  max: true
  label: true
path:
  dataset_root: datasets
  checkpoint_root: model_save
  tensorboard_root: tensorboard
  checkpoint_path: ${path.checkpoint_root}/${dataset.dataset}/mean-teacher
  tensorboard_path: ${path.tensorboard_root}/${dataset.dataset}/mean-teacher
tag: NOTAG
resume: null
download: false
stu_aug:
- type: spectrogram
  aug:
    _target_: torch.nn.Identity
tea_aug:
- type: spectrogram
  aug:
    _target_: torch.nn.Identity
slurm:
  output: /users/samova/elabbe/root_sslh/semi-supervised/logs/slurm/%j_data_gsc__method_mean-teacher__stu_aug_weak__tea_aug_weak.out
  error: /users/samova/elabbe/root_sslh/semi-supervised/logs/slurm/%j_data_gsc__method_mean-teacher__stu_aug_weak__tea_aug_weak.err
  mem_per_cpu: 9000M
  mem: ''
