{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://arxiv.org/pdf/1703.01780.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/home/lcances/.miniconda3/envs/dct/bin/python'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "import pprint\n",
    "from typing import Union\n",
    "\n",
    "import numpy\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "from torch.cuda import empty_cache\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SSL.util.loaders import load_dataset, load_optimizer, load_callbacks, load_preprocesser\n",
    "from SSL.util.model_loader import load_model\n",
    "from SSL.util.checkpoint import CheckPoint, mSummaryWriter\n",
    "from SSL.util.utils import reset_seed, get_datetime, track_maximum, DotDict\n",
    "from SSL.ramps import Warmup, sigmoid_rampup\n",
    "from SSL.losses import JensenShanon\n",
    "\n",
    "from metric_utils.metrics import CategoricalAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"esc10\", type=str)\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"wideresnet28_2\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=0.1, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=64, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=150, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.003, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_m = parser.add_argument_group(\"Model parameters\")\n",
    "group_m.add_argument(\"--num_classes\", default=35, type=int)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_s = parser.add_argument_group(\"Student teacher parameters\")\n",
    "group_s.add_argument(\"--ema_alpha\", default=0.999, type=float)\n",
    "group_s.add_argument(\"--warmup_length\", default=50, type=int)\n",
    "group_s.add_argument(\"--lambda_cost_max\", default=1, type=float)\n",
    "group_s.add_argument(\"--teacher_noise\", default=0, type=float)\n",
    "group_s.add_argument(\"--ccost_softmax\", action=\"store_false\", default=True)\n",
    "group_s.add_argument(\"--ccost_method\", type=str, default=\"mse\")\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"mean-teacher\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"mean-teacher\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_sufix\", default=\"\", type=str)\n",
    "\n",
    "args=parser.parse_args(\"\")\n",
    "\n",
    "tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "source": [
    "## Basic verification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_datasets = [\"esc10\", \"ubs8k\", \"speechcommand\"]\n",
    "available_models = [\"cnn03\", \"wideresnet28_2\", \"wideresnet28_4\", \"wideresnet28_8\"]\n",
    "available_ccost_method = [\"mse\", \"js\"]\n",
    "\n",
    "assert args.dataset in available_datasets\n",
    "assert args.model in available_models\n",
    "assert args.ccost_method in available_ccost_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 64,\n 'ccost_method': 'mse',\n 'ccost_softmax': True,\n 'checkpoint_path': 'mean-teacher',\n 'checkpoint_root': '../model_save/',\n 'dataset': 'esc10',\n 'dataset_root': '../../datasets',\n 'ema_alpha': 0.999,\n 'from_config': '',\n 'lambda_cost_max': 1,\n 'learning_rate': 0.003,\n 'model': 'wideresnet28_2',\n 'nb_epoch': 150,\n 'num_classes': 35,\n 'resume': False,\n 'seed': 1234,\n 'supervised_ratio': 0.1,\n 'teacher_noise': 0,\n 'tensorboard_path': 'mean-teacher',\n 'tensorboard_root': '../tensorboard/',\n 'tensorboard_sufix': '',\n 'train_folds': [1, 2, 3, 4],\n 'val_folds': [5],\n 'warmup_length': 50}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "reset_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL.trainers.trainers import Trainer\n",
    "\n",
    "class MeanTeacherTrainer(Trainer):\n",
    "    def __init__(self, model: str, dataset: str,\n",
    "                 ema_alpha: float = 0.999,\n",
    "                 teacher_noise_db: int = 0,\n",
    "                 warmup_length: int = 50,\n",
    "                 lambda_ccost_max: float = 1,\n",
    "                 use_softmax: bool = False,\n",
    "                 ccost_method: str = \"mse\"):\n",
    "\n",
    "        super().__init__(model, \"mean-teacher\", dataset)\n",
    "\n",
    "        self.ema_alpha = ema_alpha\n",
    "        self.teacher_noise_db = teacher_noise_db\n",
    "        self.warmup_length = warmup_length\n",
    "        self.lambda_ccost_max = lambda_ccost_max\n",
    "        self.use_softmax = use_softmax\n",
    "        self.ccost_method = ccost_method\n",
    "\n",
    "        self.extra_hparams = dict(\n",
    "            ema_alpha=self.ema_alpha,\n",
    "            teacher_noise_db=self.teacher_noise_db,\n",
    "            warmup_length=self.warmup_length,\n",
    "            lambda_ccost_max=self.lambda_ccost_max,\n",
    "            use_softmax=self.use_softmax,\n",
    "            ccost_method=self.use_softmax,\n",
    "        )\n",
    "\n",
    "        self.softmax_fn = lambda x: x\n",
    "        if self.use_softmax:\n",
    "            self.softmax_fn = nn.Softmax(dim=1)\n",
    "\n",
    "trainer = MeanTeacherTrainer(args.model, args.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load the transformation\n"
     ]
    }
   ],
   "source": [
    "trainer.load_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "def _get_input_shape(self):\n",
    "    return tuple(self.train_loader._iterables[0].dataset[0][0].shape)\n",
    "\n",
    "trainer._get_input_shape = MethodType(_get_input_shape, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load the dataset\n",
      "Dataset already downloaded and verified.\n",
      "Dataset already downloaded and verified.\n",
      "s_batch_size:  6\n",
      "u_batch_size:  58\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    \n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer.load_dataset(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(self):\n",
    "    print(\"Creating teacher and student model ...\")\n",
    "    empty_cache()\n",
    "\n",
    "    model_func = load_model(self.dataset, self.model_str)\n",
    "    model_params = dict(\n",
    "        input_shape=self.input_shape,\n",
    "        num_classes=self.num_classes,\n",
    "    )\n",
    "\n",
    "    self.student = model_func(**model_params)\n",
    "    self.teacher = model_func(**model_params)\n",
    "\n",
    "    self.student = self.student.cuda()\n",
    "    self.teacher = self.teacher.cuda()\n",
    "\n",
    "    summary(self.student, self.input_shape)\n",
    "\n",
    "trainer.create_model = MethodType(create_model, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating teacher and student model ...\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 431]             864\n",
      "       BatchNorm2d-2          [-1, 32, 64, 431]              64\n",
      "              ReLU-3          [-1, 32, 64, 431]               0\n",
      "         MaxPool2d-4          [-1, 32, 32, 216]               0\n",
      "            Conv2d-5          [-1, 32, 32, 216]           9,216\n",
      "       BatchNorm2d-6          [-1, 32, 32, 216]              64\n",
      "              ReLU-7          [-1, 32, 32, 216]               0\n",
      "            Conv2d-8          [-1, 32, 32, 216]           9,216\n",
      "       BatchNorm2d-9          [-1, 32, 32, 216]              64\n",
      "             ReLU-10          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-11          [-1, 32, 32, 216]               0\n",
      "           Conv2d-12          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 32, 216]              64\n",
      "             ReLU-14          [-1, 32, 32, 216]               0\n",
      "           Conv2d-15          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-16          [-1, 32, 32, 216]              64\n",
      "             ReLU-17          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-18          [-1, 32, 32, 216]               0\n",
      "           Conv2d-19          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-20          [-1, 32, 32, 216]              64\n",
      "             ReLU-21          [-1, 32, 32, 216]               0\n",
      "           Conv2d-22          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-23          [-1, 32, 32, 216]              64\n",
      "             ReLU-24          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-25          [-1, 32, 32, 216]               0\n",
      "           Conv2d-26          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-27          [-1, 32, 32, 216]              64\n",
      "             ReLU-28          [-1, 32, 32, 216]               0\n",
      "           Conv2d-29          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-30          [-1, 32, 32, 216]              64\n",
      "             ReLU-31          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-32          [-1, 32, 32, 216]               0\n",
      "           Conv2d-33          [-1, 64, 16, 108]          18,432\n",
      "      BatchNorm2d-34          [-1, 64, 16, 108]             128\n",
      "             ReLU-35          [-1, 64, 16, 108]               0\n",
      "           Conv2d-36          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-37          [-1, 64, 16, 108]             128\n",
      "           Conv2d-38          [-1, 64, 16, 108]           2,048\n",
      "      BatchNorm2d-39          [-1, 64, 16, 108]             128\n",
      "             ReLU-40          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-41          [-1, 64, 16, 108]               0\n",
      "           Conv2d-42          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-43          [-1, 64, 16, 108]             128\n",
      "             ReLU-44          [-1, 64, 16, 108]               0\n",
      "           Conv2d-45          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-46          [-1, 64, 16, 108]             128\n",
      "             ReLU-47          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-48          [-1, 64, 16, 108]               0\n",
      "           Conv2d-49          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-50          [-1, 64, 16, 108]             128\n",
      "             ReLU-51          [-1, 64, 16, 108]               0\n",
      "           Conv2d-52          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-53          [-1, 64, 16, 108]             128\n",
      "             ReLU-54          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-55          [-1, 64, 16, 108]               0\n",
      "           Conv2d-56          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-57          [-1, 64, 16, 108]             128\n",
      "             ReLU-58          [-1, 64, 16, 108]               0\n",
      "           Conv2d-59          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-60          [-1, 64, 16, 108]             128\n",
      "             ReLU-61          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-62          [-1, 64, 16, 108]               0\n",
      "           Conv2d-63           [-1, 128, 8, 54]          73,728\n",
      "      BatchNorm2d-64           [-1, 128, 8, 54]             256\n",
      "             ReLU-65           [-1, 128, 8, 54]               0\n",
      "           Conv2d-66           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-67           [-1, 128, 8, 54]             256\n",
      "           Conv2d-68           [-1, 128, 8, 54]           8,192\n",
      "      BatchNorm2d-69           [-1, 128, 8, 54]             256\n",
      "             ReLU-70           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 54]               0\n",
      "           Conv2d-72           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 54]             256\n",
      "             ReLU-74           [-1, 128, 8, 54]               0\n",
      "           Conv2d-75           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 54]             256\n",
      "             ReLU-77           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 54]               0\n",
      "           Conv2d-79           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 54]             256\n",
      "             ReLU-81           [-1, 128, 8, 54]               0\n",
      "           Conv2d-82           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 54]             256\n",
      "             ReLU-84           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 54]               0\n",
      "           Conv2d-86           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 54]             256\n",
      "             ReLU-88           [-1, 128, 8, 54]               0\n",
      "           Conv2d-89           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 54]             256\n",
      "             ReLU-91           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 54]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 1,472,554\n",
      "Trainable params: 1,472,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 107.11\n",
      "Params size (MB): 5.62\n",
      "Estimated Total Size (MB): 112.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trainer.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training initalization\n",
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_loss(self, parameters: DotDict):\n",
    "    self.loss_ce = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "    if self.ccost_method.lower() == \"mse\":\n",
    "        self.loss_cc = nn.MSELoss(reduction=\"mean\")\n",
    "    elif self.ccost_method.lower() == \"js\":\n",
    "        self.loss_cc = JensenShanon\n",
    "\n",
    "trainer.init_loss = MethodType(init_loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.init_loss(DotDict())"
   ]
  },
  {
   "source": [
    "## Optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_optimizer(self, parameters: DotDict):\n",
    "    print(\"Initialize optimizer\")\n",
    "    self.optimizer = load_optimizer(\n",
    "        self.dataset,\n",
    "        self.framework,\n",
    "        learning_rate=parameters.learning_rate,\n",
    "        student=self.student,\n",
    "    )\n",
    "\n",
    "trainer.init_optimizer = MethodType(init_optimizer, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initialize optimizer\n"
     ]
    }
   ],
   "source": [
    "parameters = DotDict(\n",
    "    learning_rate=args.learning_rate\n",
    ")\n",
    "\n",
    "trainer.init_optimizer(parameters)"
   ]
  },
  {
   "source": [
    "## Callbacks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_callbacks(self, parameters: DotDict):\n",
    "    print(\"Initialize callbacks\")\n",
    "    self.callbacks = load_callbacks(\n",
    "        self.dataset,\n",
    "        self.framework,\n",
    "        optimizer=self.optimizer,\n",
    "        nb_epoch=parameters.nb_epoch,\n",
    "    )\n",
    "\n",
    "    self.lambda_ccost = Warmup(self.lambda_ccost_max, self.warmup_length, sigmoid_rampup)\n",
    "    self.callbacks += [self.lambda_ccost]\n",
    "\n",
    "trainer.init_callbacks = MethodType(init_callbacks, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initialize callbacks\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    optimizer=trainer.optimizer,\n",
    ")\n",
    "trainer.init_callbacks(parameters)"
   ]
  },
  {
   "source": [
    "## Logs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_logs(self, parameters: DotDict):\n",
    "    print(\"Prepare the log system\")\n",
    "    title_element = (\n",
    "        self.model_str, parameters.supervised_ratio,\n",
    "        get_datetime(), self.model_str,\n",
    "        self.ccost_method.upper(), self.use_softmax, self.teacher_noise_db\n",
    "    )\n",
    "\n",
    "    tensorboard_title = \"%s/%sS/%s_%s_%s_%s-softmax_%s-n\" % title_element\n",
    "\n",
    "    self.tensorboard = SummaryWriter(log_dir=\"%s/%s\" % (self.tensorboard_path, tensorboard_title))\n",
    "\n",
    "trainer.init_logs = MethodType(init_logs, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prepare the log system\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_logs(parameters)"
   ]
  },
  {
   "source": [
    "## Checkpoint"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_checkpoint(self, parameters: DotDict):\n",
    "    print(\"Prepare the checkpoint system\")\n",
    "    title_element = (\n",
    "        self.model_str, parameters.supervised_ratio,\n",
    "        get_datetime(), self.model_str,\n",
    "        self.ccost_method.upper(), self.use_softmax, self.teacher_noise_db\n",
    "    )\n",
    "    \n",
    "    checkpoint_title = \"%s/%sS/%s_%s_%s_%s-softmax_%s-n\" % title_element\n",
    "\n",
    "    self.checkpoint = CheckPoint(\n",
    "        [self.student, self.teacher], self.optimizer, mode=\"max\",\n",
    "        name=f\"{self.checkpoint_path}/{checkpoint_title}\")\n",
    "\n",
    "trainer.init_checkpoint = MethodType(init_checkpoint, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prepare the checkpoint system\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_checkpoint(parameters)"
   ]
  },
  {
   "source": [
    "## Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_metrics(self, parameters: DotDict):\n",
    "    self.metrics = DotDict(\n",
    "        fscore_ss=FScore(),\n",
    "        fscore_su=FScore(),\n",
    "        fscore_ts=FScore(),\n",
    "        fscore_tu=FScore(),\n",
    "        acc_ss=CategoricalAccuracy(),\n",
    "        acc_su=CategoricalAccuracy(),\n",
    "        acc_ts=CategoricalAccuracy(),\n",
    "        acc_tu=CategoricalAccuracy(),\n",
    "        avg_Sce=ContinueAverage(),\n",
    "        avg_Tce=ContinueAverage(),\n",
    "        avg_ccost=ContinueAverage(),\n",
    "    )\n",
    "    self.maximum_tracker = track_maximum()\n",
    "\n",
    "    self.scores = DotDict()\n",
    "    for key in self.metrics:\n",
    "        self.scores[key] = []\n",
    "\n",
    "trainer.init_metrics = MethodType(init_metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.init_metrics(DotDict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_printing_form(self):\n",
    "    UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "    RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "    header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<10.8} {:<8.6} {:<8.6} {:<8.6} {:<8.6} {:<8.6} {:<8.6} | {:<10.8} {:<8.6} {:<8.6} {:<8.6} {:<8.6} {:<8.6} - {:<8.6}\"\n",
    "    value_form  = \"{:<8.8} {:<6d} - {:<6d} - {:<10.8} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} | {:<10.8} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} {:<8.4f} - {:<8.4f}\"\n",
    "    self.header = header_form.format(\".               \", \"Epoch\",  \"%\", \"Student:\", \"ce\", \"ccost\", \"acc_s\", \"f1_s\", \"acc_u\", \"f1_u\", \"Teacher:\", \"ce\", \"acc_s\", \"f1_s\", \"acc_u\", \"f1_u\" , \"Time\")\n",
    "\n",
    "    self.train_form = value_form\n",
    "    self.val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "\n",
    "trainer.set_printing_form = MethodType(set_printing_form, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_teacher_model(self, iteration):\n",
    "    \n",
    "    # Use the true average until the exponential average is more correct\n",
    "    alpha = min(1 - 1 / (iteration + 1), self.ema_alpha)\n",
    "    \n",
    "    for param, ema_param in zip(self.student.parameters(), self.teacher.parameters()):\n",
    "        ema_param.data.mul_(alpha).add_(param.data,  alpha = 1-alpha)\n",
    "\n",
    "def _noise_fn(self, x):\n",
    "    if self.teacher_noise_db == 0:\n",
    "        return x\n",
    "\n",
    "    n_db = self.teacher_noise_db\n",
    "    return x + (torch.rand(x.shape).cuda() * n_db + n_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calc_metrics(self,\n",
    "                  ss_logits, su_logits, ts_logits, tu_logits,\n",
    "                  y_s, y_u) -> Union[DotDict, DotDict]:\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        S = nn.Softmax(dim=1)\n",
    "        A = lambda x: torch.argmax(x, dim=1)\n",
    "        M = self.metrics\n",
    "\n",
    "        one_hot_s = F.one_hot(y_s, self.num_classes)\n",
    "        one_hot_u = F.one_hot(y_u, self.num_classes)\n",
    "\n",
    "        fscores = DotDict(\n",
    "            ss=M.fscore_ss(S(ss_logits), one_hot_s).mean,\n",
    "            su=M.fscore_su(S(su_logits), one_hot_u).mean,\n",
    "            ts=M.fscore_ts(S(ts_logits), one_hot_s).mean,\n",
    "            tu=M.fscore_tu(S(tu_logits), one_hot_u).mean,\n",
    "        )\n",
    "\n",
    "        accs = DotDict(\n",
    "            ss=M.acc_ss(A(ss_logits), y_s).mean,\n",
    "            su=M.acc_su(A(su_logits), y_u).mean,\n",
    "            ts=M.acc_ts(A(ts_logits), y_s).mean,\n",
    "            tu=M.acc_tu(A(tu_logits), y_u).mean,\n",
    "        )\n",
    "\n",
    "        return fscores, accs\n",
    "\n",
    "trainer._calc_metrics = MethodType(_calc_metrics, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer._update_teacher_model = MethodType(_update_teacher_model, trainer)\n",
    "trainer._noise_fn = MethodType(_noise_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def train_fn(self, epoch: int):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.train_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.student.train()\n",
    "\n",
    "    for i, (S, U) in enumerate(self.train_loader):\n",
    "        x_s, y_s = S\n",
    "        x_u, y_u = U\n",
    "\n",
    "        x_s, x_u = x_s.cuda(), x_u.cuda()\n",
    "        y_s, y_u = y_s.cuda(), y_u.cuda()\n",
    "\n",
    "        # Predictions\n",
    "        with autocast():\n",
    "            ss_logits = self.student(x_s)\n",
    "            su_logits = self.student(x_u)\n",
    "            ts_logits = self.teacher(self._noise_fn(x_s))\n",
    "            tu_logits = self.teacher(self._noise_fn(x_u))\n",
    "\n",
    "            # Calculate supervised loss (only student on S)\n",
    "            loss = self.loss_ce(ss_logits, y_s)\n",
    "\n",
    "            # Calculate consistency cost (mse(student(x), teacher(x)))\n",
    "            # x is S + U\n",
    "            student_logits = torch.cat((ss_logits, su_logits), dim=0)\n",
    "            teacher_logits = torch.cat((ts_logits, tu_logits), dim=0)\n",
    "            ccost = self.loss_cc(\n",
    "                self.softmax_fn(student_logits),\n",
    "                self.softmax_fn(teacher_logits),\n",
    "            )\n",
    "\n",
    "            total_loss = loss + self.lambda_ccost() * ccost\n",
    "\n",
    "        for p in self.student.parameters():\n",
    "            p.grad = None\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            # Teacher prediction (for metrics purpose)\n",
    "            _teacher_loss = self.loss_ce(ts_logits, y_s)\n",
    "\n",
    "            # Update teacher\n",
    "            self._update_teacher_model(epoch*nb_batch + i)\n",
    "\n",
    "            # Compute the metrics for the student\n",
    "            fscores, accs = self._calc_metrics(\n",
    "                ss_logits, su_logits,\n",
    "                ts_logits, tu_logits,\n",
    "                y_s, y_u,\n",
    "            )\n",
    "\n",
    "            # Running average of the two losses\n",
    "            student_running_loss = M.avg_Sce(loss.item()).mean\n",
    "            teacher_running_loss = M.avg_Tce(_teacher_loss.item()).mean\n",
    "            running_ccost = M.avg_ccost(ccost.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.train_form.format(\n",
    "                \"Training: \", epoch + 1, int(100 * (i + 1) / nb_batch),\n",
    "                \"\", student_running_loss, running_ccost,\n",
    "                accs.ss, fscores.ss, accs.su, fscores.su,\n",
    "                \"\", teacher_running_loss,\n",
    "                accs.ts, fscores.ts, accs.tu, fscores.tu,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"train/student_acc_s\", accs.ss, epoch)\n",
    "    T(\"train/student_acc_u\", accs.su, epoch)\n",
    "    T(\"train/student_f1_s\", fscores.ss, epoch)\n",
    "    T(\"train/student_f1_u\", fscores.su, epoch)\n",
    "\n",
    "    T(\"train/teacher_acc_s\", accs.ts, epoch)\n",
    "    T(\"train/teacher_acc_u\", accs.tu, epoch)\n",
    "    T(\"train/teacher_f1_s\", fscores.ts, epoch)\n",
    "    T(\"train/teacher_f1_u\", fscores.tu, epoch)\n",
    "\n",
    "    T(\"train/student_loss\", student_running_loss, epoch)\n",
    "    T(\"train/teacher_loss\", teacher_running_loss, epoch)\n",
    "    T(\"train/consistency_cost\", running_ccost, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "    def val_fn(self, epoch: int):\n",
    "        # aliases\n",
    "        M = self.metrics\n",
    "        T = self.tensorboard.add_scalar\n",
    "        nb_batch = len(self.val_loader)\n",
    "\n",
    "        start_time = time.time()\n",
    "        print(\"\")\n",
    "\n",
    "        self.reset_metrics()\n",
    "        self.student.eval()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            for i, (X, y) in enumerate(self.val_loader):\n",
    "                X = X.cuda()\n",
    "                y = y.cuda()\n",
    "\n",
    "                # Predictions\n",
    "                with autocast():\n",
    "                    student_logits = self.student(X)\n",
    "                    teacher_logits = self.teacher(X)\n",
    "\n",
    "                    # Calculate supervised loss (only student on S)\n",
    "                    loss = self.loss_ce(student_logits, y)\n",
    "                    _teacher_loss = self.loss_ce(teacher_logits, y)  # for metrics only\n",
    "                    ccost = self.loss_cc(\n",
    "                        self.softmax_fn(student_logits),\n",
    "                        self.softmax_fn(teacher_logits))\n",
    "\n",
    "                # Compute the metrics\n",
    "                fscores, accs = self._calc_metrics(\n",
    "                    student_logits, student_logits, \n",
    "                    teacher_logits, teacher_logits,\n",
    "                    y, y\n",
    "                )\n",
    "\n",
    "                # Running average of the two losses\n",
    "                student_running_loss = M.avg_Sce(loss.item()).mean\n",
    "                teacher_running_loss = M.avg_Tce(_teacher_loss.item()).mean\n",
    "                running_ccost = M.avg_ccost(ccost.item()).mean\n",
    "\n",
    "                # logs\n",
    "                print(self.val_form.format(\n",
    "                    \"Validation: \", epoch + 1, int(100 * (i + 1) / nb_batch),\n",
    "                    \"\", student_running_loss, running_ccost, accs.ss, fscores.ss, 0.0, 0.0,\n",
    "                    \"\", teacher_running_loss, accs.ts, fscores.ts, 0.0, 0.0,\n",
    "                    time.time() - start_time\n",
    "                ), end=\"\\r\")\n",
    "\n",
    "        self.checkpoint.step(accs.ss)\n",
    "        for c in self.callbacks:\n",
    "            c.step()\n",
    "            pass\n",
    "\n",
    "        T(\"val/student_acc\", accs.ss, epoch)\n",
    "        T(\"val/student_f1\", fscores.ss, epoch)\n",
    "        T(\"val/teacher_acc\", accs.ts, epoch)\n",
    "        T(\"val/teacher_f1\", fscores.ts, epoch)\n",
    "        T(\"val/student_loss\", student_running_loss, epoch)\n",
    "        T(\"val/teacher_loss\", teacher_running_loss, epoch)\n",
    "        T(\"val/consistency_cost\", running_ccost, epoch)\n",
    "\n",
    "        T(\"hyperparameters/learning_rate\", self._get_lr(), epoch)\n",
    "        T(\"hyperparameters/lambda_cost_max\", self.lambda_ccost(), epoch)\n",
    "\n",
    "        T(\"max/student_acc\", self.maximum_tracker(\"student_acc\", accs.ss), epoch)\n",
    "        T(\"max/teacher_acc\", self.maximum_tracker(\"teacher_acc\", accs.ts), epoch)\n",
    "        T(\"max/student_f1\", self.maximum_tracker(\"student_f1\", fscores.ss), epoch)\n",
    "        T(\"max/teacher_f1\", self.maximum_tracker(\"teacher_f1\", fscores.ts), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(self):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_printing_form = MethodType(set_printing_form, trainer)\n",
    "trainer.train_fn = MethodType(train_fn, trainer)\n",
    "trainer.val_fn = MethodType(val_fn, trainer)\n",
    "trainer.test_fn = MethodType(test_fn, trainer)\n",
    "\n",
    "trainer.set_printing_form()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "source": [
    "trainer.parameters = DotDict(\n",
    "    nb_epoch=args.nb_epoch\n",
    ")\n",
    "trainer.fit()"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   }
  },
  {
   "source": [
    "# Grid search"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params=DotDict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    learning_rate=args.learning_rate,\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    seed=args.seed,\n",
    "\n",
    ")\n",
    "other_params = dict(\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load the transformation\n",
      "Load the dataset\n",
      "Dataset already downloaded and verified.\n",
      "Dataset already downloaded and verified.\n",
      "s_batch_size:  6\n",
      "u_batch_size:  58\n",
      "Creating teacher and student model ...\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 431]             864\n",
      "       BatchNorm2d-2          [-1, 32, 64, 431]              64\n",
      "              ReLU-3          [-1, 32, 64, 431]               0\n",
      "         MaxPool2d-4          [-1, 32, 32, 216]               0\n",
      "            Conv2d-5          [-1, 32, 32, 216]           9,216\n",
      "       BatchNorm2d-6          [-1, 32, 32, 216]              64\n",
      "              ReLU-7          [-1, 32, 32, 216]               0\n",
      "            Conv2d-8          [-1, 32, 32, 216]           9,216\n",
      "       BatchNorm2d-9          [-1, 32, 32, 216]              64\n",
      "             ReLU-10          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-11          [-1, 32, 32, 216]               0\n",
      "           Conv2d-12          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 32, 216]              64\n",
      "             ReLU-14          [-1, 32, 32, 216]               0\n",
      "           Conv2d-15          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-16          [-1, 32, 32, 216]              64\n",
      "             ReLU-17          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-18          [-1, 32, 32, 216]               0\n",
      "           Conv2d-19          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-20          [-1, 32, 32, 216]              64\n",
      "             ReLU-21          [-1, 32, 32, 216]               0\n",
      "           Conv2d-22          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-23          [-1, 32, 32, 216]              64\n",
      "             ReLU-24          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-25          [-1, 32, 32, 216]               0\n",
      "           Conv2d-26          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-27          [-1, 32, 32, 216]              64\n",
      "             ReLU-28          [-1, 32, 32, 216]               0\n",
      "           Conv2d-29          [-1, 32, 32, 216]           9,216\n",
      "      BatchNorm2d-30          [-1, 32, 32, 216]              64\n",
      "             ReLU-31          [-1, 32, 32, 216]               0\n",
      "       BasicBlock-32          [-1, 32, 32, 216]               0\n",
      "           Conv2d-33          [-1, 64, 16, 108]          18,432\n",
      "      BatchNorm2d-34          [-1, 64, 16, 108]             128\n",
      "             ReLU-35          [-1, 64, 16, 108]               0\n",
      "           Conv2d-36          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-37          [-1, 64, 16, 108]             128\n",
      "           Conv2d-38          [-1, 64, 16, 108]           2,048\n",
      "      BatchNorm2d-39          [-1, 64, 16, 108]             128\n",
      "             ReLU-40          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-41          [-1, 64, 16, 108]               0\n",
      "           Conv2d-42          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-43          [-1, 64, 16, 108]             128\n",
      "             ReLU-44          [-1, 64, 16, 108]               0\n",
      "           Conv2d-45          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-46          [-1, 64, 16, 108]             128\n",
      "             ReLU-47          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-48          [-1, 64, 16, 108]               0\n",
      "           Conv2d-49          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-50          [-1, 64, 16, 108]             128\n",
      "             ReLU-51          [-1, 64, 16, 108]               0\n",
      "           Conv2d-52          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-53          [-1, 64, 16, 108]             128\n",
      "             ReLU-54          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-55          [-1, 64, 16, 108]               0\n",
      "           Conv2d-56          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-57          [-1, 64, 16, 108]             128\n",
      "             ReLU-58          [-1, 64, 16, 108]               0\n",
      "           Conv2d-59          [-1, 64, 16, 108]          36,864\n",
      "      BatchNorm2d-60          [-1, 64, 16, 108]             128\n",
      "             ReLU-61          [-1, 64, 16, 108]               0\n",
      "       BasicBlock-62          [-1, 64, 16, 108]               0\n",
      "           Conv2d-63           [-1, 128, 8, 54]          73,728\n",
      "      BatchNorm2d-64           [-1, 128, 8, 54]             256\n",
      "             ReLU-65           [-1, 128, 8, 54]               0\n",
      "           Conv2d-66           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-67           [-1, 128, 8, 54]             256\n",
      "           Conv2d-68           [-1, 128, 8, 54]           8,192\n",
      "      BatchNorm2d-69           [-1, 128, 8, 54]             256\n",
      "             ReLU-70           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 54]               0\n",
      "           Conv2d-72           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 54]             256\n",
      "             ReLU-74           [-1, 128, 8, 54]               0\n",
      "           Conv2d-75           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 54]             256\n",
      "             ReLU-77           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 54]               0\n",
      "           Conv2d-79           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 54]             256\n",
      "             ReLU-81           [-1, 128, 8, 54]               0\n",
      "           Conv2d-82           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 54]             256\n",
      "             ReLU-84           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 54]               0\n",
      "           Conv2d-86           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 54]             256\n",
      "             ReLU-88           [-1, 128, 8, 54]               0\n",
      "           Conv2d-89           [-1, 128, 8, 54]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 54]             256\n",
      "             ReLU-91           [-1, 128, 8, 54]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 54]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 1,472,554\n",
      "Trainable params: 1,472,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 107.11\n",
      "Params size (MB): 5.62\n",
      "Estimated Total Size (MB): 112.83\n",
      "----------------------------------------------------------------\n",
      "Initialize optimizer\n",
      "Initialize callbacks\n",
      "Prepare the log system\n",
      "Prepare the checkpoint system\n",
      ">>> Trainer is ready\n",
      "\n",
      "Training 1      - 100    -            2.9945   0.4903   0.1000   0.0364   0.1414   0.1129   |            2.7945   0.1000   0.0444   0.1655   0.1377   - 1.4737  \n",
      "\u001b[1;4mValidati 1      - 100    -            680.0068 192342.3594 0.1328   0.1328   0.0000   0.0000   |            2.0368   0.2656   0.1205   0.0000   0.0000   - 0.5040  \u001b[0m\n",
      "Training 2      - 100    -            2.3351   0.6342   0.1000   0.1143   0.2621   0.1341   |            2.1014   0.2667   0.0571   0.2724   0.1303   - 1.4283  \n",
      "\u001b[1;4mValidati 2      - 100    -            116.9210 32999.1230 0.1172   0.1172   0.0000   0.0000   |            2.1218   0.2031   0.0423   0.0000   0.0000   - 0.0968  \u001b[0m\n",
      " better performance: saving ...\n",
      "\n",
      "Training 3      - 100    -            2.0533   0.5517   0.2667   0.1000   0.2690   0.1971   |            1.9064   0.3000   0.0571   0.2310   0.0804   - 1.4322  \n",
      "\n",
      " better performance: saving ...\n",
      "\n",
      "Training 4      - 100    -            1.8172   0.5519   0.3333   0.0571   0.3241   0.1324   |            1.7754   0.3667   0.1143   0.2586   0.1830   - 1.4400  \n",
      "\n",
      " better performance: saving ...\n",
      "\n",
      "Training 5      - 100    -            1.5556   0.5643   0.3667   0.0571   0.3931   0.1746   |            1.4820   0.3667   0.1571   0.3793   0.1981   - 1.4360  \n",
      "\n",
      "Training 6      - 100    -            1.4429   0.4945   0.4333   0.1571   0.3897   0.2070   |            1.4408   0.6000   0.1000   0.3759   0.1886   - 1.4404  \n",
      "\u001b[1;4mValidati 6      - 100    -            1.8904   2.7096   0.3828   0.1929   0.0000   0.0000   |            1.7926   0.3516   0.1074   0.0000   0.0000   - 0.0966  \u001b[0m\n",
      "Training 7      - 100    -            1.1729   0.5558   0.6000   0.3048   0.4034   0.1810   |            1.2254   0.6000   0.3333   0.3862   0.2151   - 1.4411  \n",
      "\n",
      "Training 8      - 100    -            1.3408   0.4108   0.4333   0.1587   0.4552   0.2081   |            1.3061   0.5000   0.1714   0.3966   0.2264   - 1.4368  \n",
      "\u001b[1;4mValidati 8      - 100    -            1.7740   0.9356   0.4844   0.3552   0.0000   0.0000   |            1.6616   0.3828   0.1963   0.0000   0.0000   - 0.0964  \u001b[0m\n",
      "Training 9      - 100    -            1.5315   0.3837   0.5000   0.2571   0.4517   0.2727   |            1.5811   0.4333   0.1571   0.4034   0.2360   - 1.4336  \n",
      "\n",
      "Training 10     - 100    -            1.1479   0.3432   0.6667   0.3571   0.4897   0.3086   |            1.2771   0.6000   0.2143   0.4207   0.2584   - 1.4440  \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from SSL.trainers import MeanTeacherTrainer\n",
    "\n",
    "# learning_rate = {0.0005, 0.001, 0.003}\n",
    "# lambda_ccost = {0.5, 1, 2, 5, 10}\n",
    "# ema_alpha = {0.99, 0.999}\n",
    "\n",
    "learning_rate = {0.003}\n",
    "lambda_ccost = {1}\n",
    "ema_alpha = {0.999}\n",
    "teacher_noise_db = [0]\n",
    "\n",
    "param_list = [learning_rate, lambda_ccost, ema_alpha, teacher_noise_db]\n",
    "\n",
    "history = []\n",
    "\n",
    "for (lr, lc, ea, db) in itertools.product(*param_list):\n",
    "    trainer = MeanTeacherTrainer(\n",
    "        args.model, args.dataset,\n",
    "        lambda_ccost_max=lc,\n",
    "        ema_alpha=ea,\n",
    "        teacher_noise_db=db\n",
    "    )\n",
    "\n",
    "    training_params.learning_rate = lr\n",
    "    training_params.nb_epoch = 10\n",
    "    training_params.seed = 1234\n",
    "\n",
    "    trainer.init_trainer(training_params, **other_params)\n",
    "    trainer.set_printing_form()\n",
    "    trainer.fit()\n",
    "\n",
    "    history.append(((lr, lc, ea, db), trainer.maximum_tracker))\n",
    "\n",
    "    trainer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.003, 1, 0.999, 0, 0.546875, 0.5\n\n"
     ]
    }
   ],
   "source": [
    "with open(\".tmp.txt\", \"w\") as f:\n",
    "    f.write(\"learning_rate, lambda_ccost, ema_alpha, noise_db, acc_s, acc_t\\n\")\n",
    "    for key, value in history:\n",
    "        line = \", \".join(map(str, key)) + \\\n",
    "            \", \" + \"%s\" % value.max[\"student_acc\"].item() + \\\n",
    "            \", \" + \"%s\" % value.max[\"teacher_acc\"].item() + \\\n",
    "            \"\\n\"\n",
    "        f.write(line)\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 2160x1008 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"377.005398pt\" version=\"1.1\" viewBox=\"0 0 1711.303125 377.005398\" width=\"1711.303125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 377.005398 \nL 1711.303125 377.005398 \nL 1711.303125 -0 \nL 0 -0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 353.127273 \nL 522.456066 353.127273 \nL 522.456066 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m6292787a54\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"52.482804\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(49.301554 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"151.948045\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(148.766795 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.413285\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(248.232035 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.878526\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(347.697276 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"450.343767\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(447.162517 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"maa09368956\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maa09368956\" y=\"286.374583\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0.2 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 290.173802)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maa09368956\" y=\"210.424856\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 214.224075)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maa09368956\" y=\"134.475129\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 138.274347)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#maa09368956\" y=\"58.525402\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 62.32462)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <path clip-path=\"url(#p2aa100ca7c)\" d=\"M 52.482804 337.403306 \nL 102.215424 337.403306 \nL 151.948045 337.403306 \nL 201.680665 337.403306 \nL 251.413285 177.19685 \nL 301.145906 147.528988 \nL 350.878526 117.861126 \nL 400.611146 70.392546 \nL 450.343767 52.591829 \nL 500.076387 22.923967 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#p2aa100ca7c)\" d=\"M 52.482804 236.532574 \nL 102.215424 236.532574 \nL 151.948045 218.731857 \nL 201.680665 218.731857 \nL 251.413285 183.130423 \nL 301.145906 171.263278 \nL 350.878526 171.263278 \nL 400.611146 147.528988 \nL 450.343767 58.525402 \nL 500.076387 58.525402 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 353.127273 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 522.456066 353.127273 \nL 522.456066 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 353.127273 \nL 522.456066 353.127273 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 522.456066 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 45.1125 \nL 217.0625 45.1125 \nQ 219.0625 45.1125 219.0625 43.1125 \nL 219.0625 14.2 \nQ 219.0625 12.2 217.0625 12.2 \nL 37.103125 12.2 \nQ 35.103125 12.2 35.103125 14.2 \nL 35.103125 43.1125 \nQ 35.103125 45.1125 37.103125 45.1125 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_12\">\n     <path d=\"M 39.103125 20.298437 \nL 59.103125 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_13\"/>\n    <g id=\"text_10\">\n     <!-- max/student_acc = 0.546875 -->\n     <defs>\n      <path d=\"M 52 44.1875 \nQ 55.375 50.25 60.0625 53.125 \nQ 64.75 56 71.09375 56 \nQ 79.640625 56 84.28125 50.015625 \nQ 88.921875 44.046875 88.921875 33.015625 \nL 88.921875 0 \nL 79.890625 0 \nL 79.890625 32.71875 \nQ 79.890625 40.578125 77.09375 44.375 \nQ 74.3125 48.1875 68.609375 48.1875 \nQ 61.625 48.1875 57.5625 43.546875 \nQ 53.515625 38.921875 53.515625 30.90625 \nL 53.515625 0 \nL 44.484375 0 \nL 44.484375 32.71875 \nQ 44.484375 40.625 41.703125 44.40625 \nQ 38.921875 48.1875 33.109375 48.1875 \nQ 26.21875 48.1875 22.15625 43.53125 \nQ 18.109375 38.875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.1875 51.21875 25.484375 53.609375 \nQ 29.78125 56 35.6875 56 \nQ 41.65625 56 45.828125 52.96875 \nQ 50 49.953125 52 44.1875 \nz\n\" id=\"DejaVuSans-109\"/>\n      <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n      <path d=\"M 54.890625 54.6875 \nL 35.109375 28.078125 \nL 55.90625 0 \nL 45.3125 0 \nL 29.390625 21.484375 \nL 13.484375 0 \nL 2.875 0 \nL 24.125 28.609375 \nL 4.6875 54.6875 \nL 15.28125 54.6875 \nL 29.78125 35.203125 \nL 44.28125 54.6875 \nz\n\" id=\"DejaVuSans-120\"/>\n      <path d=\"M 25.390625 72.90625 \nL 33.6875 72.90625 \nL 8.296875 -9.28125 \nL 0 -9.28125 \nz\n\" id=\"DejaVuSans-47\"/>\n      <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n      <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      <path d=\"M 50.984375 -16.609375 \nL 50.984375 -23.578125 \nL -0.984375 -23.578125 \nL -0.984375 -16.609375 \nz\n\" id=\"DejaVuSans-95\"/>\n      <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 10.59375 45.40625 \nL 73.1875 45.40625 \nL 73.1875 37.203125 \nL 10.59375 37.203125 \nz\nM 10.59375 25.484375 \nL 73.1875 25.484375 \nL 73.1875 17.1875 \nL 10.59375 17.1875 \nz\n\" id=\"DejaVuSans-61\"/>\n      <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n     </defs>\n     <g transform=\"translate(67.103125 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"158.691406\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"217.871094\" xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"251.5625\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"303.662109\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"342.871094\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"406.25\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"469.726562\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"531.25\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"594.628906\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"633.837891\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"683.837891\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"745.117188\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"800.097656\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"855.078125\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"886.865234\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"970.654297\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1002.441406\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1066.064453\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1097.851562\" xlink:href=\"#DejaVuSans-53\"/>\n      <use x=\"1161.474609\" xlink:href=\"#DejaVuSans-52\"/>\n      <use x=\"1225.097656\" xlink:href=\"#DejaVuSans-54\"/>\n      <use x=\"1288.720703\" xlink:href=\"#DejaVuSans-56\"/>\n      <use x=\"1352.34375\" xlink:href=\"#DejaVuSans-55\"/>\n      <use x=\"1415.966797\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n    <g id=\"line2d_14\">\n     <path d=\"M 39.103125 35.254687 \nL 59.103125 35.254687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_15\"/>\n    <g id=\"text_11\">\n     <!-- max/teacher_acc = 0.5 -->\n     <defs>\n      <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     </defs>\n     <g transform=\"translate(67.103125 38.754687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"97.412109\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"158.691406\" xlink:href=\"#DejaVuSans-120\"/>\n      <use x=\"217.871094\" xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"251.5625\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"290.771484\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"352.294922\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"413.574219\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"468.554688\" xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"531.933594\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"593.457031\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"634.570312\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"684.570312\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"745.849609\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"800.830078\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"855.810547\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"887.597656\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"971.386719\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1003.173828\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1066.796875\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1098.583984\" xlink:href=\"#DejaVuSans-53\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_8\">\n    <path d=\"M 1211.750184 353.127273 \nL 1704.103125 353.127273 \nL 1704.103125 7.2 \nL 1211.750184 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_6\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1234.129863\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(1230.948613 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1333.595104\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 2 -->\n      <g transform=\"translate(1330.413854 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1433.060344\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 4 -->\n      <g transform=\"translate(1429.879094 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1532.525585\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 6 -->\n      <g transform=\"translate(1529.344335 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1631.990826\" xlink:href=\"#m6292787a54\" y=\"353.127273\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 8 -->\n      <g transform=\"translate(1628.809576 367.72571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"345.292218\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.0000 -->\n      <g transform=\"translate(1169.759559 349.091437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"291.564177\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 0.0005 -->\n      <g transform=\"translate(1169.759559 295.363395)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"237.836135\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 0.0010 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(1169.759559 241.635353)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"184.108093\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 0.0015 -->\n      <g transform=\"translate(1169.759559 187.907311)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_9\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"130.380051\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 0.0020 -->\n      <g transform=\"translate(1169.759559 134.17927)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_10\">\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"76.652009\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0.0025 -->\n      <g transform=\"translate(1169.759559 80.451228)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_11\">\n     <g id=\"line2d_27\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"1211.750184\" xlink:href=\"#maa09368956\" y=\"22.923967\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0.0030 -->\n      <g transform=\"translate(1169.759559 26.723186)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"222.65625\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"286.279297\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_28\">\n    <path clip-path=\"url(#p0737f7512e)\" d=\"M 1234.129863 22.923967 \nL 1283.862483 30.81288 \nL 1333.595104 53.707396 \nL 1383.327724 89.366441 \nL 1433.060344 134.299459 \nL 1482.792965 184.108093 \nL 1532.525585 233.916727 \nL 1582.258205 278.849745 \nL 1631.990826 314.50879 \nL 1681.723446 337.403306 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 1211.750184 353.127273 \nL 1211.750184 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 1704.103125 353.127273 \nL 1704.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 1211.750184 353.127273 \nL 1704.103125 353.127273 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 1211.750184 7.2 \nL 1704.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"legend_2\">\n    <g id=\"patch_13\">\n     <path d=\"M 1465.215625 30.15625 \nL 1697.103125 30.15625 \nQ 1699.103125 30.15625 1699.103125 28.15625 \nL 1699.103125 14.2 \nQ 1699.103125 12.2 1697.103125 12.2 \nL 1465.215625 12.2 \nQ 1463.215625 12.2 1463.215625 14.2 \nL 1463.215625 28.15625 \nQ 1463.215625 30.15625 1465.215625 30.15625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_29\">\n     <path d=\"M 1467.215625 20.298437 \nL 1487.215625 20.298437 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_30\"/>\n    <g id=\"text_24\">\n     <!-- hyperparameters/learning_rate = 0.003 -->\n     <defs>\n      <path d=\"M 32.171875 -5.078125 \nQ 28.375 -14.84375 24.75 -17.8125 \nQ 21.140625 -20.796875 15.09375 -20.796875 \nL 7.90625 -20.796875 \nL 7.90625 -13.28125 \nL 13.1875 -13.28125 \nQ 16.890625 -13.28125 18.9375 -11.515625 \nQ 21 -9.765625 23.484375 -3.21875 \nL 25.09375 0.875 \nL 2.984375 54.6875 \nL 12.5 54.6875 \nL 29.59375 11.921875 \nL 46.6875 54.6875 \nL 56.203125 54.6875 \nz\n\" id=\"DejaVuSans-121\"/>\n      <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n      <path d=\"M 45.40625 27.984375 \nQ 45.40625 37.75 41.375 43.109375 \nQ 37.359375 48.484375 30.078125 48.484375 \nQ 22.859375 48.484375 18.828125 43.109375 \nQ 14.796875 37.75 14.796875 27.984375 \nQ 14.796875 18.265625 18.828125 12.890625 \nQ 22.859375 7.515625 30.078125 7.515625 \nQ 37.359375 7.515625 41.375 12.890625 \nQ 45.40625 18.265625 45.40625 27.984375 \nz\nM 54.390625 6.78125 \nQ 54.390625 -7.171875 48.1875 -13.984375 \nQ 42 -20.796875 29.203125 -20.796875 \nQ 24.46875 -20.796875 20.265625 -20.09375 \nQ 16.0625 -19.390625 12.109375 -17.921875 \nL 12.109375 -9.1875 \nQ 16.0625 -11.328125 19.921875 -12.34375 \nQ 23.78125 -13.375 27.78125 -13.375 \nQ 36.625 -13.375 41.015625 -8.765625 \nQ 45.40625 -4.15625 45.40625 5.171875 \nL 45.40625 9.625 \nQ 42.625 4.78125 38.28125 2.390625 \nQ 33.9375 0 27.875 0 \nQ 17.828125 0 11.671875 7.65625 \nQ 5.515625 15.328125 5.515625 27.984375 \nQ 5.515625 40.671875 11.671875 48.328125 \nQ 17.828125 56 27.875 56 \nQ 33.9375 56 38.28125 53.609375 \nQ 42.625 51.21875 45.40625 46.390625 \nL 45.40625 54.6875 \nL 54.390625 54.6875 \nz\n\" id=\"DejaVuSans-103\"/>\n     </defs>\n     <g transform=\"translate(1495.215625 23.798437)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-104\"/>\n      <use x=\"63.378906\" xlink:href=\"#DejaVuSans-121\"/>\n      <use x=\"122.558594\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"186.035156\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"247.558594\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"288.671875\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"352.148438\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"413.427734\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"454.541016\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"515.820312\" xlink:href=\"#DejaVuSans-109\"/>\n      <use x=\"613.232422\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"674.755859\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"713.964844\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"775.488281\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"816.601562\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"868.701172\" xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"902.392578\" xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"930.175781\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"991.699219\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1052.978516\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1094.076172\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1157.455078\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"1185.238281\" xlink:href=\"#DejaVuSans-110\"/>\n      <use x=\"1248.617188\" xlink:href=\"#DejaVuSans-103\"/>\n      <use x=\"1312.09375\" xlink:href=\"#DejaVuSans-95\"/>\n      <use x=\"1362.09375\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"1403.207031\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"1464.486328\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"1503.695312\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"1565.21875\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1597.005859\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"1680.794922\" xlink:href=\"#DejaVuSans-32\"/>\n      <use x=\"1712.582031\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1776.205078\" xlink:href=\"#DejaVuSans-46\"/>\n      <use x=\"1807.992188\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1871.615234\" xlink:href=\"#DejaVuSans-48\"/>\n      <use x=\"1935.238281\" xlink:href=\"#DejaVuSans-51\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p2aa100ca7c\">\n   <rect height=\"345.927273\" width=\"492.352941\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n  <clipPath id=\"p0737f7512e\">\n   <rect height=\"345.927273\" width=\"492.352941\" x=\"1211.750184\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "T = trainer.tensorboard.history\n",
    "x = list(range(trainer.checkpoint.epoch_counter))\n",
    "sm = lambda y, w: np.convolve(y, np.ones(w)/w, mode='same')\n",
    "pp = lambda k: plt.plot(x, T[k], label=f\"{k} = {max(T[k])}\")\n",
    "spp = lambda k: plt.plot(x, sm(T[k], 5), label=f\"{k} = {max(T[k])}\")\n",
    "\n",
    "\n",
    "plt.figure(0, figsize=(30, 14))\n",
    "plt.subplot(2, 3, 1)\n",
    "pp(\"max/student_acc\")\n",
    "pp(\"max/teacher_acc\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "pp(\"hyperparameters/learning_rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dct",
   "language": "python",
   "name": "dct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}