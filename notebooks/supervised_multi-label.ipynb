{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/samova/lcances/.miniconda3/envs/pytorch-dev/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-80bd6afa8571>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0m__mkl_version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{MajorVersion}.{UpdateVersion}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchlibrosa.augmentation import SpecAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SSL.util.model_loader import load_model\n",
    "from SSL.util.loaders import load_dataset, load_optimizer, load_callbacks, load_preprocesser\n",
    "from SSL.util.checkpoint import CheckPoint, mSummaryWriter\n",
    "from SSL.util.utils import reset_seed, get_datetime, track_maximum, DotDict\n",
    "from SSL.util.mixup import get_mixup_fn\n",
    "\n",
    "from metric_utils.metrics import BinaryAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"audioset-unbalanced\", type=str)\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"wideresnet28_2\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=128,type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=15, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.001, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_mixup = parser.add_argument_group(\"Mixup parameters\")\n",
    "group_mixup.add_argument(\"--mixup\", action=\"store_true\", default=False)\n",
    "group_mixup.add_argument(\"--mixup_alpha\", type=float, default=0.4)\n",
    "group_mixup.add_argument(\"--mixup_max\", action=\"store_true\", default=False)\n",
    "group_mixup.add_argument(\"--mixup_label\", action=\"store_true\", default=False)\n",
    "\n",
    "group_sa = parser.add_argument_group(\"Spec augmentation\")\n",
    "group_sa.add_argument(\"--specAugment\", action=\"store_true\", default=False)\n",
    "group_sa.add_argument(\"--sa_time_drop_width\", type=int, default=32)\n",
    "group_sa.add_argument('--sa_time_stripes_mum', type=int, default=2)\n",
    "group_sa.add_argument(\"--sa_freq_drop_width\", type=int, default=4)\n",
    "group_sa.add_argument(\"--sa_freq_stripes_num\", type=int, default=2)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--log_suffix\", default=\"\", type=str)\n",
    "\n",
    "parser.add_argument(\"-N\", \"--nb_gpu\", default=1, type=int)\n",
    "\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args.tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "args.checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_config': '',\n",
       " 'dataset_root': '../datasets',\n",
       " 'dataset': 'audioset-unbalanced',\n",
       " 'model': 'wideresnet28_2',\n",
       " 'supervised_ratio': 1.0,\n",
       " 'batch_size': 128,\n",
       " 'nb_epoch': 15,\n",
       " 'learning_rate': 0.001,\n",
       " 'resume': False,\n",
       " 'seed': 1234,\n",
       " 'mixup': False,\n",
       " 'mixup_alpha': 0.4,\n",
       " 'mixup_max': False,\n",
       " 'mixup_label': False,\n",
       " 'specAugment': False,\n",
       " 'sa_time_drop_width': 32,\n",
       " 'sa_time_stripes_mum': 2,\n",
       " 'sa_freq_drop_width': 4,\n",
       " 'sa_freq_stripes_num': 2,\n",
       " 'train_folds': [1, 2, 3, 4],\n",
       " 'val_folds': [5],\n",
       " 'checkpoint_root': '../model_save/',\n",
       " 'tensorboard_root': '../tensorboard/',\n",
       " 'checkpoint_path': '../model_save/audioset-unbalanced/supervised',\n",
       " 'tensorboard_path': '../tensorboard/audioset-unbalanced/supervised',\n",
       " 'log_suffix': '',\n",
       " 'nb_gpu': 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    parameters=vars(args),\n",
    "    seed = args.seed,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# from SSL.trainers.esc import SupervisedTrainer\n",
    "from SSL.trainers.trainers import Trainer\n",
    "\n",
    "class SupervisedTrainer(Trainer):\n",
    "    def __init__(self, model: str, dataset: str):\n",
    "        super().__init__(model, \"supervised\", dataset)\n",
    "\n",
    "trainer = SupervisedTrainer(args.model, args.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the transformation\n"
     ]
    }
   ],
   "source": [
    "trainer.load_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset\n",
      "______\n",
      "eva\n",
      "['eval.h5']\n",
      "______\n",
      "unb\n",
      "['unbalanced_train_part08.h5', 'unbalanced_train_part02.h5', 'unbalanced_train_part05.h5', 'unbalanced_train_part10.h5', 'unbalanced_train_part01.h5', 'unbalanced_train_part03.h5', 'unbalanced_train_part07.h5', 'unbalanced_train_part06.h5', 'unbalanced_train_part09.h5', 'unbalanced_train_part04.h5']\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size * args.nb_gpu,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    \n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer.load_dataset(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 500]             864\n",
      "       BatchNorm2d-2          [-1, 32, 64, 500]              64\n",
      "              ReLU-3          [-1, 32, 64, 500]               0\n",
      "         MaxPool2d-4          [-1, 32, 32, 250]               0\n",
      "            Conv2d-5          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-6          [-1, 32, 32, 250]              64\n",
      "              ReLU-7          [-1, 32, 32, 250]               0\n",
      "            Conv2d-8          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-9          [-1, 32, 32, 250]              64\n",
      "             ReLU-10          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-11          [-1, 32, 32, 250]               0\n",
      "           Conv2d-12          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 32, 250]              64\n",
      "             ReLU-14          [-1, 32, 32, 250]               0\n",
      "           Conv2d-15          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-16          [-1, 32, 32, 250]              64\n",
      "             ReLU-17          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-18          [-1, 32, 32, 250]               0\n",
      "           Conv2d-19          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-20          [-1, 32, 32, 250]              64\n",
      "             ReLU-21          [-1, 32, 32, 250]               0\n",
      "           Conv2d-22          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-23          [-1, 32, 32, 250]              64\n",
      "             ReLU-24          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-25          [-1, 32, 32, 250]               0\n",
      "           Conv2d-26          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-27          [-1, 32, 32, 250]              64\n",
      "             ReLU-28          [-1, 32, 32, 250]               0\n",
      "           Conv2d-29          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-30          [-1, 32, 32, 250]              64\n",
      "             ReLU-31          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-32          [-1, 32, 32, 250]               0\n",
      "           Conv2d-33          [-1, 64, 16, 125]          18,432\n",
      "      BatchNorm2d-34          [-1, 64, 16, 125]             128\n",
      "             ReLU-35          [-1, 64, 16, 125]               0\n",
      "           Conv2d-36          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-37          [-1, 64, 16, 125]             128\n",
      "           Conv2d-38          [-1, 64, 16, 125]           2,048\n",
      "      BatchNorm2d-39          [-1, 64, 16, 125]             128\n",
      "             ReLU-40          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-41          [-1, 64, 16, 125]               0\n",
      "           Conv2d-42          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-43          [-1, 64, 16, 125]             128\n",
      "             ReLU-44          [-1, 64, 16, 125]               0\n",
      "           Conv2d-45          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-46          [-1, 64, 16, 125]             128\n",
      "             ReLU-47          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-48          [-1, 64, 16, 125]               0\n",
      "           Conv2d-49          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-50          [-1, 64, 16, 125]             128\n",
      "             ReLU-51          [-1, 64, 16, 125]               0\n",
      "           Conv2d-52          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-53          [-1, 64, 16, 125]             128\n",
      "             ReLU-54          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-55          [-1, 64, 16, 125]               0\n",
      "           Conv2d-56          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-57          [-1, 64, 16, 125]             128\n",
      "             ReLU-58          [-1, 64, 16, 125]               0\n",
      "           Conv2d-59          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-60          [-1, 64, 16, 125]             128\n",
      "             ReLU-61          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-62          [-1, 64, 16, 125]               0\n",
      "           Conv2d-63           [-1, 128, 8, 63]          73,728\n",
      "      BatchNorm2d-64           [-1, 128, 8, 63]             256\n",
      "             ReLU-65           [-1, 128, 8, 63]               0\n",
      "           Conv2d-66           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-67           [-1, 128, 8, 63]             256\n",
      "           Conv2d-68           [-1, 128, 8, 63]           8,192\n",
      "      BatchNorm2d-69           [-1, 128, 8, 63]             256\n",
      "             ReLU-70           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 63]               0\n",
      "           Conv2d-72           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 63]             256\n",
      "             ReLU-74           [-1, 128, 8, 63]               0\n",
      "           Conv2d-75           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 63]             256\n",
      "             ReLU-77           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 63]               0\n",
      "           Conv2d-79           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 63]             256\n",
      "             ReLU-81           [-1, 128, 8, 63]               0\n",
      "           Conv2d-82           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 63]             256\n",
      "             ReLU-84           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 63]               0\n",
      "           Conv2d-86           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 63]             256\n",
      "             ReLU-88           [-1, 128, 8, 63]               0\n",
      "           Conv2d-89           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 63]             256\n",
      "             ReLU-91           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 63]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                  [-1, 527]          67,983\n",
      "================================================================\n",
      "Total params: 1,539,247\n",
      "Trainable params: 1,539,247\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 124.15\n",
      "Params size (MB): 5.87\n",
      "Estimated Total Size (MB): 130.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from types import MethodType\n",
    "from torch.cuda import empty_cache\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def create_model(self, nb_gpu: int = 1):\n",
    "    print(\"Create the model\")\n",
    "    empty_cache()\n",
    "\n",
    "    model_func = load_model(self.dataset, self.model_str)\n",
    "    self.model = model_func(\n",
    "        input_shape=self.input_shape,\n",
    "        num_classes=self.num_classes,\n",
    "    )\n",
    "    self.model = self.model.cuda()\n",
    "    \n",
    "    if nb_gpu > 1:\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "\n",
    "    s = summary(self.model, self.input_shape)\n",
    "    \n",
    "trainer.create_model = MethodType(create_model, trainer)\n",
    "trainer.create_model(args.nb_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_loss(self):\n",
    "    self.loss_ce = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "trainer.init_loss = MethodType(init_loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.init_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer & callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize optimizer\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    learning_rate=args.learning_rate,\n",
    ")\n",
    "trainer.init_optimizer(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize callbacks\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    optimizer=trainer.optimizer,\n",
    ")\n",
    "trainer.init_callbacks(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the log system\n"
     ]
    }
   ],
   "source": [
    "# Logs\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_logs(parameters, suffix=args.log_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the checkpoint system\n",
      "checkpoint initialise at:  /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S\n",
      "name:  wideresnet28_2_1.0S\n",
      "mode:  max\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_checkpoint(parameters, suffix=args.log_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def init_metrics(self):\n",
    "    self.metrics = DotDict(\n",
    "        fscore_fn=FScore(),\n",
    "        acc_fn=BinaryAccuracy(),\n",
    "        avg_fn=ContinueAverage(),\n",
    "    )\n",
    "    self.maximum_tracker = track_maximum()\n",
    "\n",
    "trainer.init_metrics = MethodType(init_metrics, trainer)\n",
    "trainer.init_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_printing_form(self):\n",
    "    UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "    RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "    header_form = \"{:<8.8} {:<6.6} - {:<6.6} - {:<8.8} {:<6.6} - {:<9.9} {:<12.12}| {:<9.9}- {:<6.6}\"\n",
    "    value_form  = \"{:<8.8} {:<6} - {:<6} - {:<8.8} {:<6.4f} - {:<9.9} {:<10.4f}| {:<9.4f}- {:<6.4f}\"\n",
    "\n",
    "    self.header = header_form.format(\n",
    "        \".               \", \"Epoch\", \"%\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1 \",\"Time\"\n",
    "    )\n",
    "\n",
    "    self.train_form = value_form\n",
    "    self.val_form = UNDERLINE_SEQ + value_form + RESET_SEQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init mixup and SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec augmenter\n",
    "spec_augmenter = SpecAugmentation(time_drop_width=args.sa_time_drop_width,\n",
    "                                  time_stripes_num=args.sa_time_stripes_mum,\n",
    "                                  freq_drop_width=args.sa_freq_drop_width,\n",
    "                                  freq_stripes_num=args.sa_freq_stripes_num)\n",
    "spec_augmenter = spec_augmenter.cuda()\n",
    "\n",
    "# Mixup\n",
    "mixup_fn = get_mixup_fn(alpha=args.mixup_alpha, use_max=args.mixup_max, mix_label=args.mixup_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "batch_summed = []\n",
    "\n",
    "args.specAugment = True\n",
    "args.mixup = True\n",
    "\n",
    "def train_fn(self, epoch: int):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.train_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(self.train_loader):\n",
    "        \n",
    "        if args.specAugment:\n",
    "            X = X.view(-1, 1, *X.shape[1:])\n",
    "            X = spec_augmenter(X)\n",
    "            X = X.squeeze(1)\n",
    "\n",
    "        if args.mixup:\n",
    "            X, y = mixup_fn(X, y)\n",
    "        \n",
    "        X = X.cuda().float()\n",
    "        y = y.cuda().float()\n",
    "        \n",
    "        \n",
    "        # Skip the mini batch if the ratio is not satisfactory\n",
    "        # The files are in the batch_balancer so they will be used but later\n",
    "        with torch.set_grad_enabled(False):\n",
    "            summed = torch.sum(y, axis=0)\n",
    "            summed = summed[summed > 0]\n",
    "            ratio = min(summed) / max(summed)\n",
    "            if ratio < 0.5:\n",
    "                continue\n",
    "        \n",
    "        logits = self.model(X)\n",
    "        loss = self.loss_ce(logits, y)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            acc = M.acc_fn(logits, y).mean\n",
    "            fscore = M.fscore_fn(logits, y).mean\n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "            \n",
    "            summed = torch.sum(y, axis=0)\n",
    "            batch_summed.append(summed)\n",
    "\n",
    "            # logs\n",
    "            print(self.train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / nb_batch),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"train/Lce\", avg_ce, epoch)\n",
    "    T(\"train/f1\", fscore, epoch)\n",
    "    T(\"train/acc\", acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def val_fn(self, epoch: int):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.val_loader):\n",
    "            X = X.cuda().float()\n",
    "            y = y.cuda().float()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            acc = M.acc_fn(logits, y).mean\n",
    "            fscore = M.fscore_fn(logits, y).mean\n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                int(100 * (i + 1) / nb_batch),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"val/Lce\", avg_ce, epoch)\n",
    "    T(\"val/f1\", fscore, epoch)\n",
    "    T(\"val/acc\", acc, epoch)\n",
    "\n",
    "    T(\"hyperparameters/learning_rate\", self._get_lr(), epoch)\n",
    "\n",
    "    T(\"max/acc\", self.maximum_tracker(\"acc\", acc), epoch)\n",
    "    T(\"max/f1\", self.maximum_tracker(\"f1\", fscore), epoch)\n",
    "\n",
    "    self.checkpoint.step(fscore)\n",
    "    for c in self.callbacks:\n",
    "        c.step()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fn(self):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    # Load best epoch\n",
    "    self.checkpoint.load_best()\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.test_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            acc = M.acc_fn(pred_arg, y).mean\n",
    "            fscore = M.fscore_fn(pred, y).mean\n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Testing: \",\n",
    "                1,\n",
    "                int(100 * (i + 1) / nb_batch),\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.set_printing_form = MethodType(set_printing_form, trainer)\n",
    "trainer.train_fn = MethodType(train_fn, trainer)\n",
    "trainer.val_fn = MethodType(val_fn, trainer)\n",
    "trainer.test_fn = MethodType(test_fn, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume if wish\n",
    "if args.resume:\n",
    "    trainer.checkpoint.load_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit function\n",
    "trainer.set_printing_form()\n",
    "print(trainer.header)\n",
    "\n",
    "start_epoch = trainer.checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    trainer.train_fn(e)\n",
    "    trainer.val_fn(e)\n",
    "    \n",
    "    trainer.tensorboard.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_summed_ = batch_summed.copy()\n",
    "ratio = []\n",
    "\n",
    "for i in range(len(batch_summed)):\n",
    "    batch = batch_summed_[i].cpu()\n",
    "    batch = batch[batch > 0]\n",
    "    \n",
    "    ratio.append(min(batch) / max(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0, figsize=(20,5))\n",
    "plt.plot(ratio)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset.lower() == \"speechcommand\":\n",
    "    trainer.test_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== wideresnet28_2\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/0.5S/wideresnet28_2_0.5S.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0Smixup.best\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S.best\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0Smixup.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S.last\n",
      "======== wideresnet28_8\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_8/1.0S/wideresnet28_8_1.0S.last\n",
      "======== MobileNetV1\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/MobileNetV1/1.0S/MobileNetV1_1.0S.last\n",
      "\t /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/MobileNetV1/1.0S/MobileNetV1_1.0Smixup.last\n",
      "======== cnn14\n",
      "======== MobileNetV2\n"
     ]
    }
   ],
   "source": [
    "path_root = '/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised'\n",
    "model_dir = os.listdir(path_root)\n",
    "\n",
    "for model in model_dir:\n",
    "    print('='*8, model)\n",
    "    model_path = os.path.join(path_root, model)\n",
    "    \n",
    "    ratio_dir = os.listdir(model_path)\n",
    "    for ratio in ratio_dir:\n",
    "        ratio_path = os.path.join(model_path, ratio)\n",
    "        model_list = os.listdir(ratio_path)\n",
    "        \n",
    "        for model_save in model_list:\n",
    "            final_path = os.path.join(ratio_path, model_save)\n",
    "            print('\\t', final_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['state_dict', 'optimizer', 'epoch', 'best_metric']\n",
      "['state_dict', 'optimizer', 'epoch', 'best_metric']\n"
     ]
    }
   ],
   "source": [
    "trainer.checkpoint.load('/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0Smixup.last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 / 159\r"
     ]
    }
   ],
   "source": [
    "from metric_utils.metrics import Precision, Recall\n",
    "\n",
    "total_pred = []\n",
    "total_targets = []\n",
    "\n",
    "trainer.model.eval()\n",
    "\n",
    "nb_batch = len(trainer.val_loader)\n",
    "\n",
    "S = nn.Sigmoid()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, (X, y) in enumerate(trainer.val_loader):\n",
    "        X = X.cuda().float()\n",
    "        y = y.cuda().float()\n",
    "\n",
    "        logits = trainer.model(X)\n",
    "        \n",
    "        total_pred.append(S(logits).cpu())\n",
    "        total_targets.append(y.cpu())\n",
    "        \n",
    "        print(\"%d / %d\" % (i, nb_batch), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_ = numpy.vstack(total_pred)\n",
    "total_targets_ = numpy.vstack(total_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20352, 159)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_targets_), len(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = metrics.average_precision_score(total_targets_, total_pred_, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07668527660567237"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing mAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_targets = numpy.vstack(total_targets)\n",
    "total_pred = numpy.vstack(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 527/527 [00:01<00:00, 282.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics_auc = []\n",
    "for i in tqdm.tqdm(range(527)):\n",
    "    y = total_targets[:,i]\n",
    "    pred = total_pred[:,i]\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    metrics_auc.append(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911427144930061"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(metrics_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing d-prime\n",
    "https://stats.stackexchange.com/questions/492673/understanding-and-implementing-the-dprime-measure-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 527/527 [00:03<00:00, 162.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "Z = norm.ppf\n",
    "\n",
    "def calc_dprime(y_true, y_pred):\n",
    "    return numpy.sqrt(2) * Z(metrics.roc_auc_score(y_true,y_pred))\n",
    "\n",
    "dprimes = []\n",
    "for i in tqdm.tqdm(range(527)):\n",
    "    y = total_targets[:,i]\n",
    "    pred = total_pred[:,i]\n",
    "\n",
    "    dprimes.append(calc_dprime(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0342297967306906"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.mean(dprimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `fit` function from trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the transformation\n",
      "Load the dataset\n",
      "Dataset already downloaded and verified.\n",
      "Dataset already downloaded and verified.\n",
      "Create the model\n",
      "1872 10\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 24, 64, 431]             240\n",
      "         MaxPool2d-2          [-1, 24, 16, 215]               0\n",
      "       BatchNorm2d-3          [-1, 24, 16, 215]              48\n",
      "             ReLU6-4          [-1, 24, 16, 215]               0\n",
      "            Conv2d-5          [-1, 48, 16, 215]          10,416\n",
      "         MaxPool2d-6           [-1, 48, 4, 107]               0\n",
      "       BatchNorm2d-7           [-1, 48, 4, 107]              96\n",
      "             ReLU6-8           [-1, 48, 4, 107]               0\n",
      "            Conv2d-9           [-1, 72, 4, 107]          31,176\n",
      "        MaxPool2d-10            [-1, 72, 2, 53]               0\n",
      "      BatchNorm2d-11            [-1, 72, 2, 53]             144\n",
      "            ReLU6-12            [-1, 72, 2, 53]               0\n",
      "           Conv2d-13            [-1, 72, 2, 53]          46,728\n",
      "        MaxPool2d-14            [-1, 72, 1, 26]               0\n",
      "      BatchNorm2d-15            [-1, 72, 1, 26]             144\n",
      "            ReLU6-16            [-1, 72, 1, 26]               0\n",
      "           Conv2d-17            [-1, 72, 1, 26]          46,728\n",
      "            ReLU6-18            [-1, 72, 1, 26]               0\n",
      "          Flatten-19                 [-1, 1872]               0\n",
      "          Dropout-20                 [-1, 1872]               0\n",
      "           Linear-21                   [-1, 10]          18,730\n",
      "================================================================\n",
      "Total params: 154,450\n",
      "Trainable params: 154,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.11\n",
      "Forward/backward pass size (MB): 9.24\n",
      "Params size (MB): 0.59\n",
      "Estimated Total Size (MB): 9.93\n",
      "----------------------------------------------------------------\n",
      "Initialize optimizer\n",
      "Initialize callbacks\n",
      "Prepare the log system\n",
      "Prepare the checkpoint system\n",
      ">>> Trainer is ready\n"
     ]
    }
   ],
   "source": [
    "from SSL.trainers import SupervisedTrainer\n",
    "\n",
    "training_params=dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    learning_rate=args.learning_rate,\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    seed=args.seed,\n",
    "\n",
    ")\n",
    "other_params = dict(\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    training_params,\n",
    "    **other_params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [[1, 2, 3, 4],\n",
    "               [2, 3, 4, 5],\n",
    "               [3, 4, 5, 1],\n",
    "               [4, 5, 1, 2],\n",
    "               [5, 1, 2, 3]]\n",
    "val_folds = [[5], [1], [2], [3], [4]]\n",
    "\n",
    "for tf, vf in zip(train_folds, val_folds):\n",
    "    training_params[\"train_folds\"] = tf\n",
    "    training_params[\"val_folds\"] = vf\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "    trainer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SupervisedTrainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-23051c9f417b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupervisedTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wideresnet28_2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"esc10\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SupervisedTrainer' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seeds = np.random.randint(10000, size=(1))\n",
    "history = {}\n",
    "\n",
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [1, 2, 3, 4]\n",
    "val_folds = [5]\n",
    "seeds = np.random\n",
    "\n",
    "for seed in seeds:\n",
    "    training_params[\"train_folds\"] = [1, 2, 3, 4]\n",
    "    training_params[\"val_folds\"] = [5]\n",
    "    training_params[\"seed\"] = seed\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "\n",
    "    history[seed] = trainer.maximum_tracker\n",
    "    trainer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
