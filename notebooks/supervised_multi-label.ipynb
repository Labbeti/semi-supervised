{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/samova/lcances/.miniconda3/envs/pytorch-dev/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "os.environ[\"NUMEXPR_NU M_THREADS\"] = \"2\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "import time\n",
    "from typing import Union\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchlibrosa.augmentation import SpecAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SSL.util.model_loader import load_model\n",
    "from SSL.util.loaders import load_dataset, load_optimizer, load_callbacks, load_preprocesser\n",
    "from SSL.util.checkpoint import CheckPoint, mSummaryWriter\n",
    "from SSL.util.utils import reset_seed, get_datetime, track_maximum, DotDict\n",
    "from SSL.util.mixup import MixUpBatchShuffle\n",
    "\n",
    "from metric_utils.metrics import BinaryAccuracy, FScore, ContinueAverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--from_config\", default=\"\", type=str)\n",
    "parser.add_argument(\"-d\", \"--dataset_root\", default=\"../datasets\", type=str)\n",
    "parser.add_argument(\"-D\", \"--dataset\", default=\"audioset-unbalanced\", type=str)\n",
    "\n",
    "group_t = parser.add_argument_group(\"Commun parameters\")\n",
    "group_t.add_argument(\"-m\", \"--model\", default=\"wideresnet28_2\", type=str)\n",
    "group_t.add_argument(\"--supervised_ratio\", default=1.0, type=float)\n",
    "group_t.add_argument(\"--batch_size\", default=128, type=int)\n",
    "group_t.add_argument(\"--nb_epoch\", default=15, type=int)\n",
    "group_t.add_argument(\"--learning_rate\", default=0.003, type=float)\n",
    "group_t.add_argument(\"--resume\", action=\"store_true\", default=False)\n",
    "group_t.add_argument(\"--seed\", default=1234, type=int)\n",
    "\n",
    "group_mixup = parser.add_argument_group(\"Mixup parameters\")\n",
    "group_mixup.add_argument(\"--mixup\", action=\"store_true\", default=False)\n",
    "group_mixup.add_argument(\"--mixup_alpha\", type=float, default=0.4)\n",
    "group_mixup.add_argument(\"--mixup_max\", action=\"store_true\", default=False)\n",
    "group_mixup.add_argument(\"--mixup_label\", action=\"store_true\", default=False)\n",
    "\n",
    "group_sa = parser.add_argument_group(\"Spec augmentation\")\n",
    "group_sa.add_argument(\"--specAugment\", action=\"store_true\", default=False)\n",
    "group_sa.add_argument(\"--sa_time_drop_width\", type=int, default=32)\n",
    "group_sa.add_argument('--sa_time_stripes_mum', type=int, default=1)\n",
    "group_sa.add_argument(\"--sa_freq_drop_width\", type=int, default=4)\n",
    "group_sa.add_argument(\"--sa_freq_stripes_num\", type=int, default=1)\n",
    "\n",
    "group_u = parser.add_argument_group(\"Datasets parameters\")\n",
    "group_u.add_argument(\"-t\", \"--train_folds\", nargs=\"+\", default=[1, 2, 3, 4], type=int)\n",
    "group_u.add_argument(\"-v\", \"--val_folds\", nargs=\"+\", default=[5], type=int)\n",
    "\n",
    "group_l = parser.add_argument_group(\"Logs\")\n",
    "group_l.add_argument(\"--checkpoint_root\", default=\"../model_save/\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_root\", default=\"../tensorboard/\", type=str)\n",
    "group_l.add_argument(\"--checkpoint_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--tensorboard_path\", default=\"supervised\", type=str)\n",
    "group_l.add_argument(\"--log_suffix\", default=\"\", type=str)\n",
    "\n",
    "parser.add_argument(\"-N\", \"--nb_gpu\", default=1, type=int)\n",
    "\n",
    "\n",
    "args = parser.parse_args(['--nb_gpu', '2', '--mixup', '--mixup_alpha', '1.0', '--mixup_label'])\n",
    "\n",
    "args.tensorboard_path = os.path.join(args.tensorboard_root, args.dataset, args.tensorboard_path)\n",
    "args.checkpoint_path = os.path.join(args.checkpoint_root, args.dataset, args.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_config': '',\n",
       " 'dataset_root': '../datasets',\n",
       " 'dataset': 'audioset-unbalanced',\n",
       " 'model': 'wideresnet28_2',\n",
       " 'supervised_ratio': 1.0,\n",
       " 'batch_size': 128,\n",
       " 'nb_epoch': 15,\n",
       " 'learning_rate': 0.003,\n",
       " 'resume': False,\n",
       " 'seed': 1234,\n",
       " 'mixup': True,\n",
       " 'mixup_alpha': 1.0,\n",
       " 'mixup_max': False,\n",
       " 'mixup_label': True,\n",
       " 'specAugment': False,\n",
       " 'sa_time_drop_width': 32,\n",
       " 'sa_time_stripes_mum': 1,\n",
       " 'sa_freq_drop_width': 4,\n",
       " 'sa_freq_stripes_num': 1,\n",
       " 'train_folds': [1, 2, 3, 4],\n",
       " 'val_folds': [5],\n",
       " 'checkpoint_root': '../model_save/',\n",
       " 'tensorboard_root': '../tensorboard/',\n",
       " 'checkpoint_path': '../model_save/audioset-unbalanced/supervised',\n",
       " 'tensorboard_path': '../tensorboard/audioset-unbalanced/supervised',\n",
       " 'log_suffix': '',\n",
       " 'nb_gpu': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_seed(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    parameters=vars(args),\n",
    "    seed = args.seed,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "# from SSL.trainers.esc import SupervisedTrainer\n",
    "from SSL.trainers.trainers import Trainer\n",
    "\n",
    "class SupervisedTrainer(Trainer):\n",
    "    \n",
    "    def __init__(self, model: str, dataset: str):\n",
    "        super().__init__(model, \"supervised\", dataset)\n",
    "\n",
    "trainer = SupervisedTrainer(args.model, args.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/PyTorch/audio/torchaudio/extension/extension.py:14: UserWarning: torchaudio C++ extension is not available.\n",
      "  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "trainer.load_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the dataset\n",
      "parameters \"repeat\" set to: 114\n",
      "______\n",
      "eva\n",
      "['eval.h5']\n",
      "______\n",
      "unb\n",
      "['unbalanced_train_part08.h5', 'unbalanced_train_part02.h5', 'unbalanced_train_part05.h5', 'unbalanced_train_part10.h5', 'unbalanced_train_part01.h5', 'unbalanced_train_part03.h5', 'unbalanced_train_part07.h5', 'unbalanced_train_part06.h5', 'unbalanced_train_part09.h5', 'unbalanced_train_part04.h5']\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    \n",
    "    num_workers=10,\n",
    "    pin_memory=True,\n",
    "\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer.load_dataset(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create the model\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 500]             288\n",
      "       BatchNorm2d-2          [-1, 32, 64, 500]              64\n",
      "              ReLU-3          [-1, 32, 64, 500]               0\n",
      "         MaxPool2d-4          [-1, 32, 32, 250]               0\n",
      "            Conv2d-5          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-6          [-1, 32, 32, 250]              64\n",
      "              ReLU-7          [-1, 32, 32, 250]               0\n",
      "            Conv2d-8          [-1, 32, 32, 250]           9,216\n",
      "       BatchNorm2d-9          [-1, 32, 32, 250]              64\n",
      "             ReLU-10          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-11          [-1, 32, 32, 250]               0\n",
      "           Conv2d-12          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-13          [-1, 32, 32, 250]              64\n",
      "             ReLU-14          [-1, 32, 32, 250]               0\n",
      "           Conv2d-15          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-16          [-1, 32, 32, 250]              64\n",
      "             ReLU-17          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-18          [-1, 32, 32, 250]               0\n",
      "           Conv2d-19          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-20          [-1, 32, 32, 250]              64\n",
      "             ReLU-21          [-1, 32, 32, 250]               0\n",
      "           Conv2d-22          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-23          [-1, 32, 32, 250]              64\n",
      "             ReLU-24          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-25          [-1, 32, 32, 250]               0\n",
      "           Conv2d-26          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-27          [-1, 32, 32, 250]              64\n",
      "             ReLU-28          [-1, 32, 32, 250]               0\n",
      "           Conv2d-29          [-1, 32, 32, 250]           9,216\n",
      "      BatchNorm2d-30          [-1, 32, 32, 250]              64\n",
      "             ReLU-31          [-1, 32, 32, 250]               0\n",
      "       BasicBlock-32          [-1, 32, 32, 250]               0\n",
      "           Conv2d-33          [-1, 64, 16, 125]          18,432\n",
      "      BatchNorm2d-34          [-1, 64, 16, 125]             128\n",
      "             ReLU-35          [-1, 64, 16, 125]               0\n",
      "           Conv2d-36          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-37          [-1, 64, 16, 125]             128\n",
      "           Conv2d-38          [-1, 64, 16, 125]           2,048\n",
      "      BatchNorm2d-39          [-1, 64, 16, 125]             128\n",
      "             ReLU-40          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-41          [-1, 64, 16, 125]               0\n",
      "           Conv2d-42          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-43          [-1, 64, 16, 125]             128\n",
      "             ReLU-44          [-1, 64, 16, 125]               0\n",
      "           Conv2d-45          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-46          [-1, 64, 16, 125]             128\n",
      "             ReLU-47          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-48          [-1, 64, 16, 125]               0\n",
      "           Conv2d-49          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-50          [-1, 64, 16, 125]             128\n",
      "             ReLU-51          [-1, 64, 16, 125]               0\n",
      "           Conv2d-52          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-53          [-1, 64, 16, 125]             128\n",
      "             ReLU-54          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-55          [-1, 64, 16, 125]               0\n",
      "           Conv2d-56          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-57          [-1, 64, 16, 125]             128\n",
      "             ReLU-58          [-1, 64, 16, 125]               0\n",
      "           Conv2d-59          [-1, 64, 16, 125]          36,864\n",
      "      BatchNorm2d-60          [-1, 64, 16, 125]             128\n",
      "             ReLU-61          [-1, 64, 16, 125]               0\n",
      "       BasicBlock-62          [-1, 64, 16, 125]               0\n",
      "           Conv2d-63           [-1, 128, 8, 63]          73,728\n",
      "      BatchNorm2d-64           [-1, 128, 8, 63]             256\n",
      "             ReLU-65           [-1, 128, 8, 63]               0\n",
      "           Conv2d-66           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-67           [-1, 128, 8, 63]             256\n",
      "           Conv2d-68           [-1, 128, 8, 63]           8,192\n",
      "      BatchNorm2d-69           [-1, 128, 8, 63]             256\n",
      "             ReLU-70           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-71           [-1, 128, 8, 63]               0\n",
      "           Conv2d-72           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-73           [-1, 128, 8, 63]             256\n",
      "             ReLU-74           [-1, 128, 8, 63]               0\n",
      "           Conv2d-75           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-76           [-1, 128, 8, 63]             256\n",
      "             ReLU-77           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-78           [-1, 128, 8, 63]               0\n",
      "           Conv2d-79           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-80           [-1, 128, 8, 63]             256\n",
      "             ReLU-81           [-1, 128, 8, 63]               0\n",
      "           Conv2d-82           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-83           [-1, 128, 8, 63]             256\n",
      "             ReLU-84           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-85           [-1, 128, 8, 63]               0\n",
      "           Conv2d-86           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-87           [-1, 128, 8, 63]             256\n",
      "             ReLU-88           [-1, 128, 8, 63]               0\n",
      "           Conv2d-89           [-1, 128, 8, 63]         147,456\n",
      "      BatchNorm2d-90           [-1, 128, 8, 63]             256\n",
      "             ReLU-91           [-1, 128, 8, 63]               0\n",
      "       BasicBlock-92           [-1, 128, 8, 63]               0\n",
      "AdaptiveAvgPool2d-93            [-1, 128, 1, 1]               0\n",
      "           Linear-94                  [-1, 527]          67,983\n",
      "================================================================\n",
      "Total params: 1,538,671\n",
      "Trainable params: 1,538,671\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 124.15\n",
      "Params size (MB): 5.87\n",
      "Estimated Total Size (MB): 130.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from types import MethodType\n",
    "from torch.cuda import empty_cache\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "def create_model(self, nb_gpu: int = 1):\n",
    "    print(\"Create the model\")\n",
    "    empty_cache()\n",
    "\n",
    "    model_func = load_model(self.dataset, self.model_str)\n",
    "    self.model = model_func(\n",
    "        input_shape=self.input_shape,\n",
    "        num_classes=self.num_classes,\n",
    "    )\n",
    "    self.model = self.model.cuda()\n",
    "    \n",
    "    s = summary(self.model, self.input_shape)\n",
    "    \n",
    "    if nb_gpu > 1:\n",
    "        self.model = nn.DataParallel(self.model)\n",
    "    \n",
    "trainer.create_model = MethodType(create_model, trainer)\n",
    "trainer.create_model(args.nb_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_loss(self):\n",
    "    self.loss_ce = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "\n",
    "trainer.init_loss = MethodType(init_loss, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.init_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer & callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize optimizer\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    learning_rate=args.learning_rate,\n",
    ")\n",
    "trainer.init_optimizer(parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize callbacks\n"
     ]
    }
   ],
   "source": [
    "parameters=DotDict(\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    optimizer=trainer.optimizer,\n",
    ")\n",
    "trainer.init_callbacks(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logs and checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare suffix\n",
    "# normale training parameters\n",
    "sufix_title = ''\n",
    "sufix_title += f'_{args.learning_rate}-lr'\n",
    "sufix_title += f'_{args.supervised_ratio}-sr'\n",
    "sufix_title += f'_{args.nb_epoch}-e'\n",
    "sufix_title += f'_{args.batch_size}-bs'\n",
    "sufix_title += f'_{args.seed}-seed'\n",
    "\n",
    "# mixup parameters\n",
    "if args.mixup:\n",
    "    sufix_title += '_mixup'\n",
    "    if args.mixup_max: sufix_title += \"-max\"\n",
    "    if args.mixup_label: sufix_title += \"-label\"\n",
    "    sufix_title += f\"-{args.mixup_alpha}-a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-label-1.0-a'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sufix_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the log system\n"
     ]
    }
   ],
   "source": [
    "# Logs\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "\n",
    "trainer.init_logs(parameters, suffix=sufix_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare the checkpoint system\n",
      "checkpoint initialise at:  /users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-label-1.0-a\n",
      "name:  wideresnet28_2_1.0S_0.003-lr_1.0-sr_15-e_128-bs_1234-seed_mixup-label-1.0-a\n",
      "mode:  max\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint\n",
    "parameters=DotDict(\n",
    "    supervised_ratio=args.supervised_ratio\n",
    ")\n",
    "trainer.init_checkpoint(parameters, suffix=sufix_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "from metric_utils.metrics import Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class MAP(Metrics):\n",
    "    def __init__(self, epsilon=1e-10):\n",
    "        super().__init__(epsilon)\n",
    "\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        super().__call__(y_pred, y_true)\n",
    "        aps = metrics.average_precision_score(y_true, y_pred, average=None)\n",
    "        aps = numpy.nan_to_num(aps)\n",
    "        \n",
    "        self.values.append(aps.mean())\n",
    "        return self\n",
    "\n",
    "def init_metrics(self):\n",
    "    self.metrics = DotDict(\n",
    "        fscore_fn=FScore(),\n",
    "        acc_fn=BinaryAccuracy(),\n",
    "        avg_fn=ContinueAverage(),\n",
    "        mAP_fn=MAP()\n",
    "    )\n",
    "    self.time_average_fn = ContinueAverage()\n",
    "    \n",
    "    self.maximum_tracker = track_maximum()\n",
    "\n",
    "trainer.init_metrics = MethodType(init_metrics, trainer)\n",
    "trainer.init_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_printing_form(self):\n",
    "    UNDERLINE_SEQ = \"\\033[1;4m\"\n",
    "    RESET_SEQ = \"\\033[0m\"\n",
    "\n",
    "    header_form = \"Type            Epoch -       /       - Losses: bce       - Metrics: acc         F1           mAP           - Remaining time \"\n",
    "    header_form = \"{:<16.16} {:<5.5} - {:<5.5} / {:<5.5} - {:<7.7} {:<9.9} - {:<8.8} {:<12.12} {:<12.12} {:<12.12} - {:<6.6}\"\n",
    "    value_form  = \"{:<16.16} {:<5} - {:>5} / {:<5} - {:7.7} {:<9.4f} - {:<8.8} {:<12.3e} {:<12.3e} {:<12.3e} - {:<6.4f}\"\n",
    "\n",
    "    self.header = header_form.format(\n",
    "        \".               \", \"Epoch\", \"\", \"\", \"Losses:\", \"ce\", \"metrics: \", \"acc\", \"F1\", \"mAP\", \"Time\"\n",
    "    )\n",
    "\n",
    "    self.train_form = value_form\n",
    "    self.val_form = UNDERLINE_SEQ + value_form + RESET_SEQ\n",
    "    \n",
    "trainer.set_printing_form = MethodType(set_printing_form, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init mixup and SpecAugment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Spec augmenter\n",
    "# spec_augmenter = SpecAugmentation(time_drop_width=args.sa_time_drop_width,\n",
    "#                                   time_stripes_num=args.sa_time_stripes_mum,\n",
    "#                                   freq_drop_width=args.sa_freq_drop_width,\n",
    "#                                   freq_stripes_num=args.sa_freq_stripes_num)\n",
    "# spec_augmenter = spec_augmenter.cuda()\n",
    "\n",
    "# Mixup\n",
    "mixup_fn = MixUpBatchShuffle(alpha=args.mixup_alpha, apply_max=args.mixup_max, mix_labels=args.mixup_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "batch_summed = []\n",
    "\n",
    "\n",
    "# def calc_class_dist(y):\n",
    "#     with torch.set_grad_enabled(False):\n",
    "#         summed = torch.sum(y, axis=0)\n",
    "#         summed = summed[summed > 0]\n",
    "#         if len(summed) <= 0:\n",
    "#             return False\n",
    "\n",
    "#         ratio = min(summed) / max(summed)\n",
    "#         if ratio < 0.16:\n",
    "#             return False\n",
    "        \n",
    "#         return True\n",
    "\n",
    "def train_fn(self, epoch: int) -> Union[float, float]:\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.train_loader)\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.time_average_fn.reset()\n",
    "    self.model.train()\n",
    "\n",
    "    for i, (X, y) in enumerate(self.train_loader):\n",
    "        start_time = time.time()\n",
    "        y_ = y.detach().clone() # keep a copy outside the graph and in cpu to compute the mAP\n",
    "        \n",
    "        X = X.cuda().float()\n",
    "        y = y.cuda().float()\n",
    "        \n",
    "        if args.mixup:\n",
    "            X, y = mixup_fn(X, y)\n",
    "        \n",
    "        logits = self.model(X)\n",
    "        loss = self.loss_ce(logits, y)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        with torch.set_grad_enabled(False):\n",
    "            \n",
    "            pred = torch.sigmoid(logits)\n",
    "            \n",
    "            fscore = M.fscore_fn(pred, y)\n",
    "            acc = M.acc_fn(pred, y)\n",
    "            mAP = M.mAP_fn(pred.cpu().reshape(-1), y_.reshape(-1))\n",
    "            avg_ce = M.avg_fn(loss.item())\n",
    "\n",
    "            end_time = time.time()\n",
    "            running_mean_time = self.time_average_fn(end_time - start_time)\n",
    "            \n",
    "            # logs\n",
    "            print(self.train_form.format(\n",
    "                \"Training: \",\n",
    "                epoch + 1,\n",
    "                i, nb_batch,\n",
    "                \"\", avg_ce.value,\n",
    "                \"\", acc.mean, fscore.mean, mAP.mean,\n",
    "                (nb_batch - i) * running_mean_time.mean\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "        T(\"train/Lce\", avg_ce.mean, epoch * nb_batch + i)\n",
    "        T(\"train/f1\", fscore.mean, epoch * nb_batch + i)\n",
    "        T(\"train/acc\", acc.mean, epoch * nb_batch + i)\n",
    "        T(\"train/mAO\", mAP.mean, epoch * nb_batch + i)\n",
    "    \n",
    "    return avg_ce.mean, fscore.mean\n",
    "\n",
    "trainer.train_fn = MethodType(train_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "re_run"
    ]
   },
   "outputs": [],
   "source": [
    "def val_fn(self, epoch: int)  -> Union[float, float]:\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.val_loader):\n",
    "            X = X.cuda().float()\n",
    "            y = y.cuda().float()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            pred = torch.sigmoid(logits)\n",
    "            fscore = M.fscore_fn(pred, y)            \n",
    "            acc = M.acc_fn(pred, y)\n",
    "            mAP = M.mAP_fn(pred.cpu().reshape(-1), y.cpu().reshape(-1))\n",
    "            avg_ce = M.avg_fn(loss.item())\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Validation: \",\n",
    "                epoch + 1,\n",
    "                i, nb_batch,\n",
    "                \"\", avg_ce.mean,\n",
    "                \"\", acc.mean, fscore.mean, mAP.mean,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "\n",
    "    T(\"val/Lce\", avg_ce.mean, epoch)\n",
    "    T(\"val/f1\", fscore.mean, epoch)\n",
    "    T(\"val/acc\", acc.mean, epoch)\n",
    "\n",
    "    T(\"hyperparameters/learning_rate\", self._get_lr(), epoch)\n",
    "\n",
    "    T(\"max/acc\", self.maximum_tracker(\"acc\", acc.mean), epoch)\n",
    "    T(\"max/f1\", self.maximum_tracker(\"f1\", fscore.mean), epoch)\n",
    "    \n",
    "    return avg_ce, fscore\n",
    "    \n",
    "trainer.val_fn = MethodType(val_fn, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test_fn(self):\n",
    "    # aliases\n",
    "    M = self.metrics\n",
    "    T = self.tensorboard.add_scalar\n",
    "    nb_batch = len(self.val_loader)\n",
    "\n",
    "    # Load best epoch\n",
    "    self.checkpoint.load_best()\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"\")\n",
    "\n",
    "    self.reset_metrics()\n",
    "    self.model.eval()\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for i, (X, y) in enumerate(self.test_loader):\n",
    "            X = X.cuda()\n",
    "            y = y.cuda()\n",
    "\n",
    "            logits = self.model(X)\n",
    "            loss = self.loss_ce(logits, y)\n",
    "\n",
    "            pred = torch.sigmoid(logits)\n",
    "            y_one_hot = y # F.one_hot(y, num_classes=self.num_classes)\n",
    "            fscore = M.fscore_fn(pred, y_one_hot).mean\n",
    "            \n",
    "            acc = M.acc_fn(logits, y).mean\n",
    "            \n",
    "            avg_ce = M.avg_fn(loss.item()).mean\n",
    "\n",
    "            # logs\n",
    "            print(self.val_form.format(\n",
    "                \"Testing: \",\n",
    "                1,\n",
    "                i, nb_batch,\n",
    "                \"\", avg_ce,\n",
    "                \"\", acc, fscore,\n",
    "                time.time() - start_time\n",
    "            ), end=\"\\r\")\n",
    "            \n",
    "    return avg_ce, fscore\n",
    "            \n",
    "trainer.test_fn = MethodType(test_fn, trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume if wish\n",
    "if args.resume:\n",
    "    trainer.checkpoint.load_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".                Epoch -       /       - Losses: ce        - metrics: acc          F1           mAP          - Time  \n",
      "\n",
      "Training:        1     -  1263 / 15950 -         0.0032    -          9.954e-01    1.577e-05    1.951e-02    - 3083.84175\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/samova/lcances/.miniconda3/envs/pytorch-dev/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:681: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:        1     - 15949 / 15950 -         0.0005    -          9.971e-01    3.113e-02    9.707e-02    - 0.2127405\n",
      "\u001b[1;4mValidation:      1     -   158 / 159   -         0.0216    -          9.957e-01    3.878e-02    1.262e-01    - 57.6719\u001b[0m\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FScore' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c202c6a54644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# checkpoint save depend on fscore value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_fscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Apply the different callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semi-supervised/SSL/util/checkpoint.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, new_value)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# save best epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_better\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n better performance: saving ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/semi-supervised/SSL/util/checkpoint.py\u001b[0m in \u001b[0;36m_check_is_better\u001b[0;34m(self, new_value)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_is_better\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# The case of 0-d tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FScore' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Fit function\n",
    "trainer.set_printing_form()\n",
    "print(trainer.header)\n",
    "\n",
    "start_epoch = trainer.checkpoint.epoch_counter\n",
    "end_epoch = args.nb_epoch\n",
    "\n",
    "for e in range(start_epoch, args.nb_epoch):\n",
    "    # Perform train and validation step\n",
    "    train_avg_ce, train_fscore = trainer.train_fn(e)\n",
    "    val_avg_ce, val_fscore = trainer.val_fn(e)\n",
    "    \n",
    "    # checkpoint save depend on fscore value\n",
    "    trainer.checkpoint.step(val_fscore.mean)\n",
    "    \n",
    "    # Apply the different callbacks\n",
    "    for c in trainer.callbacks:\n",
    "        c.step()\n",
    "    \n",
    "    trainer.tensorboard.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_summed_ = batch_summed.copy()\n",
    "ratio = []\n",
    "\n",
    "for i in range(len(batch_summed)):\n",
    "    batch = batch_summed_[i].cpu()\n",
    "    batch = batch[batch > 0]\n",
    "    \n",
    "    ratio.append(min(batch) / max(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0, figsize=(20,5))\n",
    "plt.plot(ratio)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset.lower() == \"speechcommand\":\n",
    "    trainer.test_fn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ♫♪.ılılıll|̲̅̅●̲̅̅|̲̅̅=̲̅̅|̲̅̅●̲̅̅|llılılı.♫♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_root = '/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised'\n",
    "model_dir = os.listdir(path_root)\n",
    "\n",
    "for model in model_dir:\n",
    "    print('='*8, model)\n",
    "    model_path = os.path.join(path_root, model)\n",
    "    \n",
    "    ratio_dir = os.listdir(model_path)\n",
    "    for ratio in ratio_dir:\n",
    "        ratio_path = os.path.join(model_path, ratio)\n",
    "        model_list = os.listdir(ratio_path)\n",
    "        \n",
    "        for model_save in model_list:\n",
    "            final_path = os.path.join(ratio_path, model_save)\n",
    "            print('\\t', final_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.checkpoint.load('/users/samova/lcances/semi-supervised/model_save/audioset-unbalanced/supervised/wideresnet28_2/1.0S/wideresnet28_2_1.0S.best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from metric_utils.metrics import Precision, Recall\n",
    "\n",
    "total_pred = []\n",
    "total_targets = []\n",
    "\n",
    "trainer.model.eval()\n",
    "\n",
    "nb_batch = len(trainer.val_loader)\n",
    "\n",
    "S = nn.Sigmoid()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for i, (X, y) in enumerate(trainer.val_loader):\n",
    "        X = X.cuda().float()\n",
    "        y = y.cuda().float()\n",
    "\n",
    "        logits = trainer.model(X)\n",
    "        \n",
    "        total_pred.append(S(logits).cpu())\n",
    "        total_targets.append(y.cpu())\n",
    "        \n",
    "        print(\"%d / %d\" % (i, nb_batch), end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pred_ = numpy.vstack(total_pred)\n",
    "total_targets_ = numpy.vstack(total_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(total_targets_), len(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP = metrics.average_precision_score(total_targets_, total_pred_, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing mAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_targets = numpy.vstack(total_targets)\n",
    "total_pred = numpy.vstack(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics_auc = []\n",
    "for i in tqdm.tqdm(range(527)):\n",
    "    y = total_targets[:,i]\n",
    "    pred = total_pred[:,i]\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
    "    metrics_auc.append(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.mean(metrics_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing d-prime\n",
    "https://stats.stackexchange.com/questions/492673/understanding-and-implementing-the-dprime-measure-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "Z = norm.ppf\n",
    "\n",
    "def calc_dprime(y_true, y_pred):\n",
    "    return numpy.sqrt(2) * Z(metrics.roc_auc_score(y_true,y_pred))\n",
    "\n",
    "dprimes = []\n",
    "for i in tqdm.tqdm(range(527)):\n",
    "    y = total_targets[:,i]\n",
    "    pred = total_pred[:,i]\n",
    "\n",
    "    dprimes.append(calc_dprime(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.mean(dprimes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `fit` function from trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSL.trainers import SupervisedTrainer\n",
    "\n",
    "training_params=dict(\n",
    "    dataset=args.dataset,\n",
    "\n",
    "    dataset_root = args.dataset_root,\n",
    "    supervised_ratio = args.supervised_ratio,\n",
    "    batch_size = args.batch_size,\n",
    "    train_folds = args.train_folds,\n",
    "    val_folds = args.val_folds,\n",
    "    learning_rate=args.learning_rate,\n",
    "    nb_epoch=args.nb_epoch,\n",
    "    seed=args.seed,\n",
    "\n",
    ")\n",
    "other_params = dict(\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    verbose = 2,\n",
    ")\n",
    "\n",
    "trainer = SupervisedTrainer(\"cnn03\", \"esc10\")\n",
    "trainer.init_trainer(\n",
    "    training_params,\n",
    "    **other_params\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [[1, 2, 3, 4],\n",
    "               [2, 3, 4, 5],\n",
    "               [3, 4, 5, 1],\n",
    "               [4, 5, 1, 2],\n",
    "               [5, 1, 2, 3]]\n",
    "val_folds = [[5], [1], [2], [3], [4]]\n",
    "\n",
    "for tf, vf in zip(train_folds, val_folds):\n",
    "    training_params[\"train_folds\"] = tf\n",
    "    training_params[\"val_folds\"] = vf\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "    trainer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seeds = np.random.randint(10000, size=(1))\n",
    "history = {}\n",
    "\n",
    "trainer = SupervisedTrainer(\"wideresnet28_2\", \"esc10\")\n",
    "\n",
    "train_folds = [1, 2, 3, 4]\n",
    "val_folds = [5]\n",
    "seeds = np.random\n",
    "\n",
    "for seed in seeds:\n",
    "    training_params[\"train_folds\"] = [1, 2, 3, 4]\n",
    "    training_params[\"val_folds\"] = [5]\n",
    "    training_params[\"seed\"] = seed\n",
    "\n",
    "    trainer.init_trainer(\n",
    "        training_params,\n",
    "        **other_params\n",
    "    )\n",
    "\n",
    "    trainer.fit()\n",
    "\n",
    "    history[seed] = trainer.maximum_tracker\n",
    "    trainer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-dev",
   "language": "python",
   "name": "pytorch-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
